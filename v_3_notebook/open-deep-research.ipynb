{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Note about the PDFs:\n",
    "\n",
    "I personally got direct permission from Ron Kohavi to use his book, papers, and LinkedIn posts (which I scrapped) as part of this PDF collection. When I share this notebook on Github, I will not include the 'data' subdirectory to keep it private and secure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State\n",
    "\n",
    "The state structure organizes all the information needed to generate and refine a report on a given topic through multiple steps. Here’s a breakdown:\n",
    "\n",
    "- **Report-Level State:**  \n",
    "  - **Topic:** The overall subject of the report.  \n",
    "  - **Feedback on Report Plan:** Comments or evaluations on the preliminary report outline.  \n",
    "  - **Sections:** A list of individual report sections (each with its own name, description, whether research is needed, and content).  \n",
    "  - **Completed Sections:** A collection of sections that have been fully developed, which is also used by downstream processes (e.g., a Send() API).  \n",
    "  - **Research-Based Content:** A string that gathers content produced from web research, which may be integrated into the final report.  \n",
    "  - **Final Report:** The completed report after all sections and revisions are combined.\n",
    "\n",
    "- **Section-Level State:**  \n",
    "  For each report section, the state captures:  \n",
    "  - **Section Details:** Including the section’s name, a brief overview (description), a flag indicating if web research should be performed, and the actual content.  \n",
    "  - **Search Process:** The number of search iterations that have been executed and a list of search queries used to gather information.  \n",
    "  - **Source Content:** A formatted string containing the relevant material obtained from current iteration's web searches (for writer)\n",
    "  - **Source Content All:** A formatted string containing the relevant material obtained from all iterations' web searches (for user display)\n",
    "  - **Integration:** Both the research-derived content and the list of fully completed sections are tracked to ensure they can be merged into the overall report.\n",
    "\n",
    "- **Search Queries and Feedback:**  \n",
    "  - **Search Queries:** Represented as individual query objects, these encapsulate the strings used to perform web searches.  \n",
    "  - **Feedback:** After generating parts of the report, feedback is provided as a grade (either \"pass\" or \"fail\") along with any follow-up queries to improve the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"Name for this section of the report.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
    "    )\n",
    "    research: bool = Field(\n",
    "        description=\"Whether to perform web research for this section of the report.\"\n",
    "    )\n",
    "    content: str = Field(\n",
    "        description=\"The content of the section.\"\n",
    "    )   \n",
    "    sources: str = Field(\n",
    "        default=\"\", \n",
    "        description=\"All sources used for this section\"\n",
    "    )\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"Sections of the report.\",\n",
    "    )\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Query for web search.\")\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[SearchQuery] = Field(\n",
    "        description=\"List of search queries.\",\n",
    "    )\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"pass\",\"fail\"] = Field(\n",
    "        description=\"Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail').\"\n",
    "    )\n",
    "    follow_up_queries: List[SearchQuery] = Field(\n",
    "        description=\"List of follow-up search queries.\",\n",
    "    )\n",
    "\n",
    "class ReportStateInput(TypedDict):\n",
    "    topic: str # Report topic\n",
    "    \n",
    "class ReportStateOutput(TypedDict):\n",
    "    final_report: str # Final report\n",
    "\n",
    "class ReportState(TypedDict):\n",
    "    topic: str # Report topic    \n",
    "    feedback_on_report_plan: str # Feedback on the report plan\n",
    "    sections: list[Section] # List of report sections \n",
    "    completed_sections: Annotated[list, operator.add] # Send() API key\n",
    "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
    "    final_report: str # Final report\n",
    "\n",
    "class SectionState(TypedDict):\n",
    "    topic: str # Report topic\n",
    "    section: Section # Report section  \n",
    "    search_iterations: int # Number of search iterations done\n",
    "    search_queries: list[SearchQuery] # List of search queries\n",
    "    source_str: str # String of formatted source content from current iteration web search (for writer)\n",
    "    source_str_all: str  # All accumulated sources (for user display)\n",
    "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
    "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
    "\n",
    "class SectionOutputState(TypedDict):\n",
    "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities and Helpers\n",
    "\n",
    "We have a number of utility functions that we'll use to build our graph. Let's take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import requests\n",
    "\n",
    "from tavily import TavilyClient, AsyncTavilyClient\n",
    "from langchain_community.retrievers import ArxivRetriever\n",
    "from typing import List, Optional, Dict, Any\n",
    "from langsmith import traceable\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "tavily_async_client = AsyncTavilyClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is a small helper that makes sure your configuration values are in a consistent format. If you pass in a string, it simply returns that string. However, if you pass in an enum (a special type of value), it will extract and return the underlying value of that enum. This helps when your configuration might come in different types but you need to work with strings consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_value(value):\n",
    "    \"\"\"\n",
    "    Helper function to handle both string and enum cases of configuration values\n",
    "    \"\"\"\n",
    "    return value if isinstance(value, str) else value.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function filters a configuration dictionary so that it only includes parameters that are allowed for a specific search API. It works by looking up a list of accepted parameter names for the given API (like “exa” or “pubmed”) and then stripping out any other entries from the configuration. If no configuration is provided, it simply returns an empty dictionary. This ensures that only valid and expected parameters are sent to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get search parameters based on the search API and config\n",
    "def get_search_params(search_api: str, search_api_config: Optional[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Filters the search_api_config dictionary to include only parameters accepted by the specified search API.\n",
    "\n",
    "    Args:\n",
    "        search_api (str): The search API identifier (e.g., \"tavily\").\n",
    "        search_api_config (Optional[Dict[str, Any]]): The configuration dictionary for the search API.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary of parameters to pass to the search function.\n",
    "    \"\"\"\n",
    "    # Define accepted parameters for each search API\n",
    "    SEARCH_API_PARAMS = {\n",
    "        \"rag\": [],  # RAG currently accepts no additional parameters\n",
    "        \"arxiv\": [\"load_max_docs\", \"get_full_documents\", \"load_all_available_meta\"],\n",
    "        \"tavily\": []  # Tavily currently accepts no additional parameters\n",
    "\n",
    "    }\n",
    "\n",
    "    # Get the list of accepted parameters for the given search API\n",
    "    accepted_params = SEARCH_API_PARAMS.get(search_api, [])\n",
    "\n",
    "    # If no config provided, return an empty dict\n",
    "    if not search_api_config:\n",
    "        return {}\n",
    "\n",
    "    # Filter the config to only include accepted parameters\n",
    "    return {k: v for k, v in search_api_config.items() if k in accepted_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_search_type(search_iterations):\n",
    "    if search_iterations == 0:\n",
    "        return \"RAG search (internal A/B testing knowledge base)\"\n",
    "    elif search_iterations == 1:  \n",
    "        return \"ArXiv web search (search academic papers on arXiv)\"\n",
    "    else:\n",
    "        return \"tavily web search (general web sources)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a collection of search results—possibly from several responses—and formats them into a neat, human-readable string. It starts by combining all the results and then removes any duplicates (using the title to check for repeats if a RAG source, otherwise using the URL to check for repeats). For each unique source, it prints out the title (and URL if not RAG source). If enabled, it also includes a trimmed version of the full source content, ensuring that the text does not exceed a specified token limit. This results in a clean, consolidated overview of your search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True, search_iterations=None, return_has_sources=False):\n",
    "    \"\"\"\n",
    "    Takes a list of search responses and formats them into a readable string.\n",
    "    Limits the raw_content to approximately max_tokens_per_source.\n",
    " \n",
    "    Args:\n",
    "        search_responses: List of search response dicts, each containing:\n",
    "            - query: str\n",
    "            - results: List of dicts with fields:\n",
    "                - title: str\n",
    "                - url: str\n",
    "                - content: str\n",
    "                - score: float\n",
    "                - raw_content: str|None\n",
    "        max_tokens_per_source: int\n",
    "        include_raw_content: bool\n",
    "        search_iterations: int, optional\n",
    "            If 0, deduplicate by title (for RAG results) and show only title\n",
    "            Otherwise, deduplicate by URL (for web/arxiv results) and show title + URL\n",
    "        return_has_sources: bool, optional\n",
    "            If True, returns (formatted_string, has_sources_bool)\n",
    "            If False, returns just formatted_string \n",
    "            \n",
    "    Returns:\n",
    "        str OR tuple: \n",
    "            - If return_has_sources=False: formatted string\n",
    "            - If return_has_sources=True: (formatted_string, has_sources_bool)\n",
    "    \"\"\"\n",
    "    # Collect all results\n",
    "    sources_list = []\n",
    "    for response in search_response:\n",
    "        sources_list.extend(response['results'])\n",
    "    \n",
    "    if not sources_list:\n",
    "        empty_result = \"\"\n",
    "        return (empty_result, False) if return_has_sources else empty_result\n",
    "    \n",
    "    # Deduplicate by title if search_iterations == 0 (RAG), otherwise by URL\n",
    "    if search_iterations == 0:\n",
    "        unique_sources = {source['title']: source for source in sources_list}\n",
    "    else:\n",
    "        unique_sources = {source['url']: source for source in sources_list}\n",
    "\n",
    "    # Check if we have unique sources after deduplication\n",
    "    has_unique_sources = bool(unique_sources)\n",
    "    \n",
    "    if not unique_sources:\n",
    "        empty_result = \"\"\n",
    "        return (empty_result, False) if return_has_sources else empty_result\n",
    "\n",
    "    # Format output\n",
    "    formatted_text = \"\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"{source['title']}\\n===\\n\"\n",
    "        \n",
    "        # Only show URL if not RAG results (search_iterations != 0)\n",
    "        if search_iterations != 0:\n",
    "            formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        \n",
    "        if include_raw_content:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "                formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens \\n\\n\"\n",
    "                \n",
    "    final_result = formatted_text.strip()\n",
    "    return (final_result, has_unique_sources) if return_has_sources else final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designed to help organize documentation or reports, this function takes a list of section objects and turns them into a well-formatted string. For each section, it prints a header with the section number and name, followed by its description, any research notes, and the main content (or a placeholder if the content isn’t written yet). The output is clearly separated by visual dividers, making it easy to read and understand the structure of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sections(sections: list[Section]) -> str:\n",
    "    \"\"\" Format a list of sections into a string \"\"\"\n",
    "    formatted_str = \"\"\n",
    "    for idx, section in enumerate(sections, 1):\n",
    "        formatted_str += f\"\"\"\n",
    "{'='*60} # divider line of 60 equal signs\n",
    "Section {idx}: {section.name}\n",
    "{'='*60} # divider line of 60 equal signs\n",
    "Description:\n",
    "{section.description}\n",
    "Requires Research: \n",
    "{section.research}\n",
    "\n",
    "Content:\n",
    "{section.content if section.content else '[Not yet written]'}\n",
    "\n",
    "\"\"\"\n",
    "    return formatted_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs multiple web searches concurrently using the Tavily API. You simply provide it with a list of search queries, and it creates asynchronous tasks for each one. The function then gathers all the responses together, each containing details like the title, URL, snippet of content, and optionally the raw content. This is particularly useful when you need to search several queries at once without waiting for each one to finish sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "async def tavily_search_async(search_queries):\n",
    "    \"\"\"\n",
    "    Performs concurrent web searches using the Tavily API.\n",
    "\n",
    "    Args:\n",
    "        search_queries (List[SearchQuery]): List of search queries to process\n",
    "\n",
    "    Returns:\n",
    "            List[dict]: List of search responses from Tavily API, one per query. Each response has format:\n",
    "                {\n",
    "                    'query': str, # The original search query\n",
    "                    'follow_up_questions': None,      \n",
    "                    'answer': None,\n",
    "                    'images': list,\n",
    "                    'results': [                     # List of search results\n",
    "                        {\n",
    "                            'title': str,            # Title of the webpage\n",
    "                            'url': str,              # URL of the result\n",
    "                            'content': str,          # Summary/snippet of content\n",
    "                            'score': float,          # Relevance score\n",
    "                            'raw_content': str|None  # Full page content if available\n",
    "                        },\n",
    "                        ...\n",
    "                    ]\n",
    "                }\n",
    "    \"\"\"\n",
    "    \n",
    "    search_tasks = []\n",
    "    for query in search_queries:\n",
    "            search_tasks.append(\n",
    "                tavily_async_client.search(\n",
    "                    query,\n",
    "                    max_results=5,\n",
    "                    include_raw_content=True,\n",
    "                    topic=\"general\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Execute all searches concurrently\n",
    "    search_docs = await asyncio.gather(*search_tasks)\n",
    "\n",
    "    return search_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is tailored for searching academic papers on arXiv. It runs asynchronously, so it can handle multiple queries without blocking. For each search query, it initializes an arXiv retriever that gathers documents along with their metadata (like authors, publication dates, and summaries). The results are then formatted to include useful details such as a link to the paper and even a link to the PDF if available. It also assigns a relevance score to each paper and respects arXiv’s rate limits by adding delays between requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "async def arxiv_search_async(search_queries, load_max_docs=5, get_full_documents=True, load_all_available_meta=True):\n",
    "    \"\"\"\n",
    "    Performs concurrent searches on arXiv using the ArxivRetriever.\n",
    "\n",
    "    Args:\n",
    "        search_queries (List[str]): List of search queries or article IDs\n",
    "        load_max_docs (int, optional): Maximum number of documents to return per query. Default is 5.\n",
    "        get_full_documents (bool, optional): Whether to fetch full text of documents. Default is True.\n",
    "        load_all_available_meta (bool, optional): Whether to load all available metadata. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: List of search responses from arXiv, one per query. Each response has format:\n",
    "            {\n",
    "                'query': str,                    # The original search query\n",
    "                'follow_up_questions': None,      \n",
    "                'answer': None,\n",
    "                'images': [],\n",
    "                'results': [                     # List of search results\n",
    "                    {\n",
    "                        'title': str,            # Title of the paper\n",
    "                        'url': str,              # URL (Entry ID) of the paper\n",
    "                        'content': str,          # Formatted summary with metadata\n",
    "                        'score': float,          # Relevance score (approximated)\n",
    "                        'raw_content': str|None  # Full paper content if available\n",
    "                    },\n",
    "                    ...\n",
    "                ]\n",
    "            }\n",
    "    \"\"\"\n",
    "    \n",
    "    async def process_single_query(query):\n",
    "        try:\n",
    "            # Create retriever for each query\n",
    "            retriever = ArxivRetriever(\n",
    "                load_max_docs=load_max_docs,\n",
    "                get_full_documents=get_full_documents,\n",
    "                load_all_available_meta=load_all_available_meta\n",
    "            )\n",
    "            \n",
    "            # Run the synchronous retriever in a thread pool\n",
    "            loop = asyncio.get_event_loop()\n",
    "            docs = await loop.run_in_executor(None, lambda: retriever.invoke(query))\n",
    "            \n",
    "            results = []\n",
    "            # Assign decreasing scores based on the order\n",
    "            base_score = 1.0\n",
    "            score_decrement = 1.0 / (len(docs) + 1) if docs else 0\n",
    "            \n",
    "            for i, doc in enumerate(docs):\n",
    "                # Extract metadata\n",
    "                metadata = doc.metadata\n",
    "                \n",
    "                # Use entry_id as the URL (this is the actual arxiv link)\n",
    "                url = metadata.get('entry_id', '')\n",
    "                \n",
    "                # Format content with all useful metadata\n",
    "                content_parts = []\n",
    "\n",
    "                # Primary information\n",
    "                if 'Summary' in metadata:\n",
    "                    content_parts.append(f\"Summary: {metadata['Summary']}\")\n",
    "\n",
    "                if 'Authors' in metadata:\n",
    "                    content_parts.append(f\"Authors: {metadata['Authors']}\")\n",
    "\n",
    "                # Add publication information\n",
    "                published = metadata.get('Published')\n",
    "                published_str = published.isoformat() if hasattr(published, 'isoformat') else str(published) if published else ''\n",
    "                if published_str:\n",
    "                    content_parts.append(f\"Published: {published_str}\")\n",
    "\n",
    "                # Add additional metadata if available\n",
    "                if 'primary_category' in metadata:\n",
    "                    content_parts.append(f\"Primary Category: {metadata['primary_category']}\")\n",
    "\n",
    "                if 'categories' in metadata and metadata['categories']:\n",
    "                    content_parts.append(f\"Categories: {', '.join(metadata['categories'])}\")\n",
    "\n",
    "                if 'comment' in metadata and metadata['comment']:\n",
    "                    content_parts.append(f\"Comment: {metadata['comment']}\")\n",
    "\n",
    "                if 'journal_ref' in metadata and metadata['journal_ref']:\n",
    "                    content_parts.append(f\"Journal Reference: {metadata['journal_ref']}\")\n",
    "\n",
    "                if 'doi' in metadata and metadata['doi']:\n",
    "                    content_parts.append(f\"DOI: {metadata['doi']}\")\n",
    "\n",
    "                # Get PDF link if available in the links\n",
    "                pdf_link = \"\"\n",
    "                if 'links' in metadata and metadata['links']:\n",
    "                    for link in metadata['links']:\n",
    "                        if 'pdf' in link:\n",
    "                            pdf_link = link\n",
    "                            content_parts.append(f\"PDF: {pdf_link}\")\n",
    "                            break\n",
    "\n",
    "                # Join all content parts with newlines \n",
    "                content = \"\\n\".join(content_parts)\n",
    "                \n",
    "                result = {\n",
    "                    'title': metadata.get('Title', ''),\n",
    "                    'url': url,  # Using entry_id as the URL\n",
    "                    'content': content,\n",
    "                    'score': base_score - (i * score_decrement),\n",
    "                    'raw_content': doc.page_content if get_full_documents else None\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "            return {\n",
    "                'query': query,\n",
    "                'follow_up_questions': None,\n",
    "                'answer': None,\n",
    "                'images': [],\n",
    "                'results': results\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # Handle exceptions gracefully\n",
    "            print(f\"Error processing arXiv query '{query}': {str(e)}\")\n",
    "            return {\n",
    "                'query': query,\n",
    "                'follow_up_questions': None,\n",
    "                'answer': None,\n",
    "                'images': [],\n",
    "                'results': [],\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Process queries sequentially with delay to respect arXiv rate limit (1 request per 3 seconds)\n",
    "    search_docs = []\n",
    "    for i, query in enumerate(search_queries):\n",
    "        try:\n",
    "            # Add delay between requests (3 seconds per ArXiv's rate limit)\n",
    "            if i > 0:  # Don't delay the first request\n",
    "                await asyncio.sleep(3.0)\n",
    "            \n",
    "            result = await process_single_query(query)\n",
    "            search_docs.append(result)\n",
    "        except Exception as e:\n",
    "            # Handle exceptions gracefully\n",
    "            print(f\"Error processing arXiv query '{query}': {str(e)}\")\n",
    "            search_docs.append({\n",
    "                'query': query,\n",
    "                'follow_up_questions': None,\n",
    "                'answer': None,\n",
    "                'images': [],\n",
    "                'results': [],\n",
    "                'error': str(e)\n",
    "            })\n",
    "            \n",
    "            # Add additional delay if we hit a rate limit error\n",
    "            if \"429\" in str(e) or \"Too Many Requests\" in str(e):\n",
    "                print(\"ArXiv rate limit exceeded. Adding additional delay...\")\n",
    "                await asyncio.sleep(5.0)  # Add a longer delay if we hit a rate limit\n",
    "    \n",
    "    return search_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add our RAG tool to be able to access our collection of Ron Kohavi's work. We first load the processed chunks and our fine-tuned embedding model and then set up our retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to the saved JSON file\n",
    "with open(\"all_chunks_95percentile.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_chunks_95percentile = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "all_chunks_95percentile = [Document(page_content=chunk['page_content'], \n",
    "                      metadata=chunk['metadata']) \n",
    "              for chunk in all_chunks_95percentile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# c. Page load time (performance)\\n\\nProposed MDE for power calculations: 1% for 250 msec slowdown (70% of 0.6%*250/100 msec) if done on all pages. [Updated 3/2025] Lower MDE of 0.2% if done for a page (e.g., just search).'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks_95percentile[342].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at kamkol/ab_testing_finetuned_arctic_ft-36dfff22-0696-40d2-b3bf-268fe2ff2aec and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"kamkol/ab_testing_finetuned_arctic_ft-36dfff22-0696-40d2-b3bf-268fe2ff2aec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/qdrant_client/http/models/models.py:758: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  description=\"Check that the field is empty, alternative syntax for `is_empty: \\&quot;field_name\\&quot;`\",\n",
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/qdrant_client/http/models/models.py:762: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  description=\"Check that the field is null, alternative syntax for `is_null: \\&quot;field_name\\&quot;`\",\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "qdrant_vectorstore = Qdrant.from_documents(\n",
    "    all_chunks_95percentile,\n",
    "    embedding_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"kohavi_ab_testing_pdf_collection\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a retriever that will return the top 5 documents for a given query\n",
    "\n",
    "qdrant_retriever = qdrant_vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(all_chunks_95percentile)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        qdrant_retriever, \n",
    "        bm25_retriever\n",
    "    ],\n",
    "    weights=[0.5, 0.5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "cohere_rerank = CohereRerank(\n",
    "    model=\"rerank-english-v3.0\",\n",
    "    top_n=5,\n",
    ")\n",
    "\n",
    "reranker = ContextualCompressionRetriever(\n",
    "    base_compressor=cohere_rerank, base_retriever=hybrid_retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/x_4x8xps7lqf2rzdt9mhf_y80000gn/T/ipykernel_24771/4139670063.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(reranker.get_relevant_documents(\"What is False Positive Risk?\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'Pvalue Misinterpretations Annotated References.pdf', 'section_title': '4. The reproducibility of research and the misinterpretation of p-values (2017) by David Colquhoun.', 'section_level': 1, 'section_id': 'sec_1_1260037657844929439', 'chunk_type': 'text', '_id': '00df71f5197e4fac8bc63d5ab7dae046', '_collection_name': 'kohavi_ab_testing_pdf_collection', 'relevance_score': 0.9979493}, page_content='# 4. The reproducibility of research and the misinterpretation of p-values (2017) by David Colquhoun. Great paper about False Positive Risk. This article has only 256 citations, but I found it extremely insightful about the difference between alpha of 0.05 (what he calls p-less-than) and actually seeing a p-value around 0.05 (what he calls p-equals). In our Intuition Busters paper, we gave the false positive risk of p-less-than, which is much smaller than p-equals. 1. “…if the prior probability of a real effect were only 0.1. And, in this case, if you wanted to achieve a false positive risk of 5% you would need to observe p=0.00045.”\\n2. “p-values should be supplemented by specifying the prior probability that would be needed to produce a specified (e.g. 5%) false positive risk.”\\n3. “When you have done an experiment, you want to know whether you have made a discovery or whether your results could have occurred by chance. More precisely, what you want to know is when a statistical test of significance comes out positive, what the probability is that you have a false positive, i.e. there is no real effect and the results have occurred by chance.'), Document(metadata={'source': 'Pvalue Misinterpretations Annotated References.pdf', 'section_title': 'Untitled', 'section_level': 0, 'section_id': 'sec_0_-8297853168768162974', 'chunk_type': 'text', '_id': '76cfa14f00c14415bd28c6b293c6f32d', '_collection_name': 'kohavi_ab_testing_pdf_collection', 'relevance_score': 0.99298817}, page_content='https://bit.ly/pvalueMisinterpretations\\n\\nGoogle Ads, and Netflix, will have a false-positive-risk of about 24% for alpha &lt; 0.05 (two-tailed, so 0.025 for the positive tail), but for the experiments with a p-value of 0.05 (two-tailed), the false-positive risk is 63.4%! g.'), Document(metadata={'source': 'Pvalue Misinterpretations Annotated References.pdf', 'section_title': '4. The reproducibility of research and the misinterpretation of p-values (2017) by David Colquhoun.', 'section_level': 1, 'section_id': 'sec_1_1260037657844929439', 'chunk_type': 'text', '_id': '9e4ce1789b0949bd9cfe1ac10561e337', '_collection_name': 'kohavi_ab_testing_pdf_collection', 'relevance_score': 0.9920312}, page_content='This probability is defined here as the false positive risk (FPR).”\\n4. “…Real life can only be worse, so in that sense the results given here are the most optimistic possible.”\\n5. “what is the probability that our results occurred by chance if, in a single unbiased test, we find p=0.047 (or whatever value is observed)? Is it appropriate to consider all tests that produce p≤0.047 or should we consider only tests that give p=0.047? Let us call these, respectively, the ‘p-less-than’ interpretation and the ‘p-equals’ interpretations….In other words, the p-equals case is what we need to answer our question.”\\n6. This graph shows the p-less-than and p-equals when the experiment is powered at 78% (it’s not 80% because he uses simulations on small n). Note that at p-value of 0.05, the p-less-than FPR is 36.5%, but the p-equals is 76.6%. Because we usually use a two-tailed test, but are interested in the positive tail only, plugging in 0.025 results in FPR of 24.9% for the p-less-than and 59.6% for the p-equals case. Increasing the power by putting 121,600 (16*0.05*0.95/(0.05*0.05)^2) as the sample size and effect size of .011471 (as multiple of SD, which is 0.05*0.05/sqrt(0.05*0.95)), gives FPR of 23.8% for the p-less-than and 63.4% for the p-equals case. The former is close to the 22% in the Intuition Busters paper.'), Document(metadata={'source': 'Pvalue Misinterpretations Annotated References.pdf', 'section_title': 'Redefine statistical significance (2017) by Benjamin et al.', 'section_level': 1, 'section_id': 'sec_1_-9168131747058846148', 'chunk_type': 'text', '_id': '3dc17a6f62e54cefb6458a537a345d74', '_collection_name': 'kohavi_ab_testing_pdf_collection', 'relevance_score': 0.9728308}, page_content='I suspect every word mattered when reviewed by 72 co-authors. I love the fact that they show two arguments for lowering the alpha threshold: a Bayesian argument, and a False-Positive-Rate/Risk (FPR). 1. “…we believe that a leading cause of non-reproducibility has not yet been adequately addressed: statistical standards of evidence for claiming new discoveries in many fields of science are simply too low. Associating statistically significant findings with P < 0.05 results in a high rate of false positives even in the absence of other experimental, procedural and reporting problems. For fields where the threshold for defining statistical significance for new discoveries is P < 0.05, we propose a change to P < 0.005.”\\n2. “Results that would currently be called significant but do not meet the new threshold should instead be called suggestive.”\\n3. “Prediction markets and analyses of replication results both suggest that for psychology experiments, the prior odds of H1 relative to H0 may be only about 1:10. A similar number has been suggested in cancer clinical trials, and the number is likely to be much lower in preclinical biomedical research.” In software, the results for many companies are around 1:10, as shown in A/B Testing Intuition Busters. 4. “A two-sided P value of 0.05 corresponds to Bayes factors in favor of H1 that range from about 2.5 to 3.4 under reasonable assumptions about H1… prior odds of 1:10, a P value of 0.05 corresponds to at least 3:1 odds ..in favor of the null hypothesis!”\\n5. “…the false positive rate is greater than 33% with prior odds of 1:10 and a P value threshold of 0.05, regardless of the level of statistical power. Reducing the threshold to 0.005 would reduce this minimum false positive rate to 5%.”\\n6. For objections, they note the following: “The false negative rate would become unacceptably high. Evidence that does not reach the new significance threshold should be treated as suggestive, and where possible further evidence should be accumulated; indeed, the combined results from several studies may be compelling even if any particular…”'), Document(metadata={'source': 'Online Controlled Experiments at Large Scale.pdf', 'section_title': '5.1 False Positives', 'section_level': 1, 'section_id': 'sec_1_923351243397566463', 'chunk_type': 'text', '_id': '69c61e4435c3437e9189f2fbe6339f60', '_collection_name': 'kohavi_ab_testing_pdf_collection', 'relevance_score': 0.89552265}, page_content='# 5.1 False Positives\\n\\nFalse positives are “positive findings” that are not actually true. In any large scale system false positives are a commonplace given the many ways in which we violate the assumption of a single hypothesis test done once.')]\n"
     ]
    }
   ],
   "source": [
    "print(reranker.get_relevant_documents(\"What is False Positive Risk?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "async def rag_search_async(search_queries):\n",
    "    \"\"\"\n",
    "    Performs concurrent RAG searches of our thorough A/B testing collection using the reranker.\n",
    "\n",
    "    Args:\n",
    "        search_queries (List[SearchQuery]): List of search queries to process\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: List of search responses from RAG, one per query. Each response has format:\n",
    "            {\n",
    "                'query': str, # The original search query\n",
    "                'follow_up_questions': None,      \n",
    "                'answer': None,\n",
    "                'images': list,\n",
    "                'results': [                     # List of search results\n",
    "                    {\n",
    "                        'title': str,            # Title in format \"Kohavi: {title}, Section: {section}\"\n",
    "                        'url': str,              # None for RAG results\n",
    "                        'content': str,          # None for RAG results\n",
    "                        'score': float,          # None for RAG results\n",
    "                        'raw_content': str|None  # Chunk's page_content\n",
    "                    },\n",
    "                    ...\n",
    "                ]\n",
    "            }\n",
    "    \"\"\"\n",
    "    \n",
    "    async def single_rag_search(query):\n",
    "        # Retrieve documents. It's a best practice to return contexts in ascending order\n",
    "        docs_descending = reranker.get_relevant_documents(query)\n",
    "        docs = docs_descending[::-1]\n",
    "        \n",
    "        # Format each document as a result\n",
    "        results = []\n",
    "        for doc in docs:\n",
    "            source_path = doc.metadata.get(\"source\", \"\")\n",
    "            filename = source_path.split(\"/\")[-1] if \"/\" in source_path else source_path\n",
    "\n",
    "            # Remove .pdf extension if present\n",
    "            if filename.endswith('.pdf'):\n",
    "                filename = filename[:-4]\n",
    "\n",
    "            section = doc.metadata.get(\"section_title\", \"unknown\")\n",
    "            \n",
    "            title = f\"Kohavi: {filename}, Section: {section}\"\n",
    "            \n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'url': None,\n",
    "                'content': None,\n",
    "                'score': None,\n",
    "                'raw_content': doc.page_content\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'follow_up_questions': None,\n",
    "            'answer': None,\n",
    "            'images': [],\n",
    "            'results': results\n",
    "        }\n",
    "    \n",
    "    # Create tasks for concurrent execution\n",
    "    search_tasks = [single_rag_search(query) for query in search_queries]\n",
    "    \n",
    "    # Execute all searches concurrently\n",
    "    search_responses = await asyncio.gather(*search_tasks)\n",
    "    \n",
    "    return search_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'What is False Positive Risk?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Kohavi: Online Controlled Experiments at Large Scale, Section: 5.1 False Positives', 'url': None, 'content': None, 'score': None, 'raw_content': '# 5.1 False Positives\\n\\nFalse positives are “positive findings” that are not actually true. In any large scale system false positives are a commonplace given the many ways in which we violate the assumption of a single hypothesis test done once.'}, {'title': 'Kohavi: Pvalue Misinterpretations Annotated References, Section: Redefine statistical significance (2017) by Benjamin et al.', 'url': None, 'content': None, 'score': None, 'raw_content': 'I suspect every word mattered when reviewed by 72 co-authors. I love the fact that they show two arguments for lowering the alpha threshold: a Bayesian argument, and a False-Positive-Rate/Risk (FPR). 1. “…we believe that a leading cause of non-reproducibility has not yet been adequately addressed: statistical standards of evidence for claiming new discoveries in many fields of science are simply too low. Associating statistically significant findings with P < 0.05 results in a high rate of false positives even in the absence of other experimental, procedural and reporting problems. For fields where the threshold for defining statistical significance for new discoveries is P < 0.05, we propose a change to P < 0.005.”\\n2. “Results that would currently be called significant but do not meet the new threshold should instead be called suggestive.”\\n3. “Prediction markets and analyses of replication results both suggest that for psychology experiments, the prior odds of H1 relative to H0 may be only about 1:10. A similar number has been suggested in cancer clinical trials, and the number is likely to be much lower in preclinical biomedical research.” In software, the results for many companies are around 1:10, as shown in A/B Testing Intuition Busters. 4. “A two-sided P value of 0.05 corresponds to Bayes factors in favor of H1 that range from about 2.5 to 3.4 under reasonable assumptions about H1… prior odds of 1:10, a P value of 0.05 corresponds to at least 3:1 odds ..in favor of the null hypothesis!”\\n5. “…the false positive rate is greater than 33% with prior odds of 1:10 and a P value threshold of 0.05, regardless of the level of statistical power. Reducing the threshold to 0.005 would reduce this minimum false positive rate to 5%.”\\n6. For objections, they note the following: “The false negative rate would become unacceptably high. Evidence that does not reach the new significance threshold should be treated as suggestive, and where possible further evidence should be accumulated; indeed, the combined results from several studies may be compelling even if any particular…”'}, {'title': 'Kohavi: Pvalue Misinterpretations Annotated References, Section: 4. The reproducibility of research and the misinterpretation of p-values (2017) by David Colquhoun.', 'url': None, 'content': None, 'score': None, 'raw_content': 'This probability is defined here as the false positive risk (FPR).”\\n4. “…Real life can only be worse, so in that sense the results given here are the most optimistic possible.”\\n5. “what is the probability that our results occurred by chance if, in a single unbiased test, we find p=0.047 (or whatever value is observed)? Is it appropriate to consider all tests that produce p≤0.047 or should we consider only tests that give p=0.047? Let us call these, respectively, the ‘p-less-than’ interpretation and the ‘p-equals’ interpretations….In other words, the p-equals case is what we need to answer our question.”\\n6. This graph shows the p-less-than and p-equals when the experiment is powered at 78% (it’s not 80% because he uses simulations on small n). Note that at p-value of 0.05, the p-less-than FPR is 36.5%, but the p-equals is 76.6%. Because we usually use a two-tailed test, but are interested in the positive tail only, plugging in 0.025 results in FPR of 24.9% for the p-less-than and 59.6% for the p-equals case. Increasing the power by putting 121,600 (16*0.05*0.95/(0.05*0.05)^2) as the sample size and effect size of .011471 (as multiple of SD, which is 0.05*0.05/sqrt(0.05*0.95)), gives FPR of 23.8% for the p-less-than and 63.4% for the p-equals case. The former is close to the 22% in the Intuition Busters paper.'}, {'title': 'Kohavi: Pvalue Misinterpretations Annotated References, Section: Untitled', 'url': None, 'content': None, 'score': None, 'raw_content': 'https://bit.ly/pvalueMisinterpretations\\n\\nGoogle Ads, and Netflix, will have a false-positive-risk of about 24% for alpha &lt; 0.05 (two-tailed, so 0.025 for the positive tail), but for the experiments with a p-value of 0.05 (two-tailed), the false-positive risk is 63.4%! g.'}, {'title': 'Kohavi: Pvalue Misinterpretations Annotated References, Section: 4. The reproducibility of research and the misinterpretation of p-values (2017) by David Colquhoun.', 'url': None, 'content': None, 'score': None, 'raw_content': '# 4. The reproducibility of research and the misinterpretation of p-values (2017) by David Colquhoun. Great paper about False Positive Risk. This article has only 256 citations, but I found it extremely insightful about the difference between alpha of 0.05 (what he calls p-less-than) and actually seeing a p-value around 0.05 (what he calls p-equals). In our Intuition Busters paper, we gave the false positive risk of p-less-than, which is much smaller than p-equals. 1. “…if the prior probability of a real effect were only 0.1. And, in this case, if you wanted to achieve a false positive risk of 5% you would need to observe p=0.00045.”\\n2. “p-values should be supplemented by specifying the prior probability that would be needed to produce a specified (e.g. 5%) false positive risk.”\\n3. “When you have done an experiment, you want to know whether you have made a discovery or whether your results could have occurred by chance. More precisely, what you want to know is when a statistical test of significance comes out positive, what the probability is that you have a false positive, i.e. there is no real effect and the results have occurred by chance.'}]}]\n"
     ]
    }
   ],
   "source": [
    "result = await rag_search_async([\"What is False Positive Risk?\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Planner and Configurations\n",
    "\n",
    "This code defines a configuration system for a chatbot that generates reports. Here's a breakdown of its components:\n",
    "\n",
    "1. **Default Report Structure:**  \n",
    "   A multi-line string provides a template for creating reports. It suggests starting with an introduction that gives an overview of the topic, then dividing the main content into sections focused on sub-topics, and finally ending with a conclusion that summarizes the main points.\n",
    "\n",
    "2. **Enumerated Types (Enums):**  \n",
    "   - **SearchAPI:** Lists possible search services (TAVILY, ARXIV, and RAG) that the chatbot might use to gather information.\n",
    "   - **PlannerProvider & WriterProvider:** These define options for external service providers that handle planning (organizing the report structure) and writing (generating the text). Options include providers like ANTHROPIC, OPENAI.\n",
    "\n",
    "3. **Configuration Data Class:**  \n",
    "   The `Configuration` class holds various settings for the chatbot. Key attributes include:\n",
    "   - **report_structure:** Uses the default report template.\n",
    "   - **number_of_queries:** Specifies how many search queries should be generated in each iteration (default is 1).\n",
    "   - **max_search_depth:** Sets the limit for how many times the chatbot can iterate through reflection and search (default is 3).\n",
    "   - **planner_provider & planner_model:** Determine which external service and model to use for planning the report.\n",
    "   - **writer_provider & writer_model:** Specify the external service and model for generating the report text.\n",
    "   - **search_api & search_api_config:** Indicate which search API to use and allow for additional API configuration.\n",
    "\n",
    "4. **Configuration Initialization Method:**  \n",
    "   The class method `from_runnable_config` allows the configuration to be created from a provided configuration object (or from environment variables). It checks for values in the environment (using uppercase names) and from a passed configuration dictionary. Only fields with provided values are used to instantiate the `Configuration` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, fields\n",
    "from typing import Any, Optional, Dict \n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from dataclasses import dataclass\n",
    "\n",
    "DEFAULT_REPORT_STRUCTURE = \"\"\"Use this structure to create a report on the user-provided topic:\n",
    "\n",
    "1. Introduction (no research needed)\n",
    "   - Brief overview of the topic area\n",
    "\n",
    "2. Main Body Sections:\n",
    "   - Each section should focus on a sub-topic of the user-provided topic\n",
    "   \n",
    "3. Conclusion\n",
    "   - Aim for 1 structural element (either a list of table) that distills the main body sections \n",
    "   - Provide a concise summary of the report\n",
    "   \n",
    "Provide a paragraph with no more than 500 words to describe the key take aways on the topic\"\"\"\n",
    "\n",
    "# Enum classes in Python create sets of named constants with unique values\n",
    "class SearchAPI(Enum):\n",
    "    TAVILY = \"tavily\"\n",
    "    ARXIV = \"arxiv\"\n",
    "    RAG = \"rag\"\n",
    "\n",
    "class PlannerProvider(Enum):\n",
    "    ANTHROPIC = \"anthropic\"\n",
    "    OPENAI = \"openai\"\n",
    "\n",
    "class WriterProvider(Enum):\n",
    "    ANTHROPIC = \"anthropic\"\n",
    "    OPENAI = \"openai\"\n",
    "\n",
    "# Dataclasses automatically generate boilerplate code for classes that primarily store data\n",
    "# Dataclasses automatically create __init__, __repr__, __eq__ methods\n",
    "@dataclass(kw_only=True)\n",
    "class Configuration:\n",
    "    \"\"\"The configurable fields for the chatbot.\"\"\"\n",
    "    report_structure: str = DEFAULT_REPORT_STRUCTURE # Defaults to the default report structure\n",
    "\n",
    "    ### SET THESE NUMBERS HIGHER FOR A LARGER / MORE DETAILED REPORT - YOU MAY RUN INTO RATE LIMITING ISSUES\n",
    "    number_of_queries: int = 1 # Number of search queries to generate per iteration\n",
    "    max_search_depth: int = 3 # Maximum number of reflection + search iterations\n",
    "\n",
    "    ### UNCOMMENT BELOW IF YOU RUN INTO RATE LIMIT ISSUES\n",
    "    # planner_provider: PlannerProvider = PlannerProvider.OPENAI  # Defaults to OpenAI as provider\n",
    "    # planner_model: str = \"o3-mini\" # Defaults to o3-mini, add \"-thinking\" to enable thinking mode\n",
    "    # writer_provider: WriterProvider = WriterProvider.OPENAI # Defaults to OpenAI as provider\n",
    "    #writer_model: str = \"o3-mini\" # Defaults to o3-mini\n",
    "\n",
    "    ### COMMENT BELOW IF YOU RUN INTO RATE LIMIT ISSUES\n",
    "    planner_provider: PlannerProvider = PlannerProvider.ANTHROPIC  # Defaults to Anthropic as provider\n",
    "    planner_model: str = \"claude-opus-4-20250514\" # Defaults to claude-opus-4-20250514\n",
    "    writer_provider: WriterProvider = WriterProvider.ANTHROPIC # Defaults to Anthropic as provider\n",
    "    writer_model: str = \"claude-sonnet-4-20250514\" # Defaults to claude-sonnet-4-20250514\n",
    "\n",
    "    \n",
    "    search_api: SearchAPI = SearchAPI.TAVILY # Default to TAVILY\n",
    "    search_api_config: Optional[Dict[str, Any]] = None \n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "        values: dict[str, Any] = {\n",
    "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
    "            for f in fields(cls)\n",
    "            if f.init\n",
    "        }\n",
    "        return cls(**{k: v for k, v in values.items() if v})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "These templates are used to guide the chatbot's behavior in different stages of report generation: \n",
    "\n",
    "1. **Report Planner Query Writer:**  \n",
    "   This prompt generates search queries to help with planning the report structure. It asks the model to create queries that will gather information for each section of the report.\n",
    "\n",
    "2. **Report Plan:**  \n",
    "   This prompt generates a plan for the report. It asks the model to create a list of sections for the report.\n",
    "\n",
    "3. **Section Writer:**  \n",
    "   This prompt generates a section of the report. It asks the model to write a section of the report based on the provided section topic and existing content.\n",
    "\n",
    "4. **Section Grader:**  \n",
    "   This prompt grades a section of the report. It asks the model to evaluate whether the section content adequately addresses the section topic.\n",
    "\n",
    "5. **Final Section Writer:**  \n",
    "   This prompt generates the final section of the report. It asks the model to write a section of the report that synthesizes information from the rest of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to generate search queries to help with planning the report\n",
    "report_planner_query_writer_instructions=\"\"\"You are performing research for a report. \n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Report organization>\n",
    "{report_organization}\n",
    "</Report organization>\n",
    "\n",
    "<Task>\n",
    "Your goal is to generate {number_of_queries} web search queries that will help gather information for planning the report sections. \n",
    "\n",
    "The queries should:\n",
    "\n",
    "1. Be related to the Report topic\n",
    "2. Help satisfy the requirements specified in the report organization\n",
    "\n",
    "Make the queries specific enough to find high-quality, relevant sources while covering the breadth needed for the report structure.\n",
    "</Task>\n",
    "\"\"\"\n",
    "\n",
    "# Prompt to generate the report plan\n",
    "report_planner_instructions=\"\"\"I want a plan for a report that is concise and focused.\n",
    "\n",
    "<Report topic>\n",
    "The topic of the report is:\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Report organization>\n",
    "The report should follow this organization: \n",
    "{report_organization}\n",
    "</Report organization>\n",
    "\n",
    "<Context>\n",
    "Here is context to use to plan the sections of the report: \n",
    "{context}\n",
    "</Context>\n",
    "\n",
    "<Task>\n",
    "Generate a list of sections for the report. Your plan should be tight and focused with NO overlapping sections or unnecessary filler. \n",
    "\n",
    "For example, a good report structure might look like:\n",
    "1/ intro\n",
    "2/ overview of topic A\n",
    "3/ overview of topic B\n",
    "4/ comparison between A and B\n",
    "5/ conclusion\n",
    "\n",
    "Each section should have the fields:\n",
    "\n",
    "- Name - Name for this section of the report.\n",
    "- Description - Brief overview of the main topics covered in this section.\n",
    "- Research - Whether to perform web research for this section of the report.\n",
    "- Content - The content of the section, which you will leave blank for now.\n",
    "\n",
    "Integration guidelines:\n",
    "- Include examples and implementation details within main topic sections, not as separate sections\n",
    "- Ensure each section has a distinct purpose with no content overlap\n",
    "- Combine related concepts rather than separating them\n",
    "\n",
    "Before submitting, review your structure to ensure it has no redundant sections and follows a logical flow.\n",
    "</Task>\n",
    "\n",
    "<Feedback>\n",
    "Here is feedback on the report structure from review (if any):\n",
    "{feedback}\n",
    "</Feedback>\n",
    "\"\"\"\n",
    "\n",
    "# Query writer instructions\n",
    "query_writer_instructions=\"\"\"You are an expert technical writer crafting targeted web search queries that will gather comprehensive information for writing a technical report section.\n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Section topic>\n",
    "{section_topic}\n",
    "</Section topic>\n",
    "\n",
    "<Task>\n",
    "Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information above the section topic. \n",
    "\n",
    "The queries should:\n",
    "\n",
    "1. Be related to the topic \n",
    "2. Examine different aspects of the topic\n",
    "\n",
    "Make the queries specific enough to find high-quality, relevant sources.\n",
    "</Task>\n",
    "\"\"\"\n",
    "\n",
    "# Section writer instructions\n",
    "section_writer_instructions = \"\"\"You are an expert technical writer crafting one section of a technical report.\n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Section name>\n",
    "{section_name}\n",
    "</Section name>\n",
    "\n",
    "<Section topic>\n",
    "{section_topic}\n",
    "</Section topic>\n",
    "\n",
    "<Existing section content (if populated)>\n",
    "{section_content}\n",
    "</Existing section content>\n",
    "\n",
    "<Source material>\n",
    "{context}\n",
    "</Source material>\n",
    "\n",
    "\n",
    "<Guidelines for writing>\n",
    "1. If the existing section content is not populated, write a new section from scratch.\n",
    "2. If the existing section content is populated, write a new section that synthesizes the existing section content with the Source material. If there is a discrepancy between the existing section content and the Source material, use the existing section content as the primary source. The purpose of the Source material is to provide additional information and context to help fill the gaps in the existing section content.\n",
    "</Guidelines for writing>\n",
    "\n",
    "<Length and style>\n",
    "- Strict 150-200 word limit\n",
    "- No marketing language\n",
    "- Technical focus\n",
    "- Write in simple, clear language\n",
    "- Start with your most important insight in **bold**\n",
    "- Use short paragraphs (2-3 sentences max)\n",
    "- Use ## for section title (Markdown format)\n",
    "- Only use ONE structural element IF it helps clarify your point:\n",
    "  * Either a focused table comparing 2-3 key items (using Markdown table syntax)\n",
    "  * Or a short list (3-5 items) using proper Markdown list syntax:\n",
    "    - Use `*` or `-` for unordered lists\n",
    "    - Use `1.` for ordered lists\n",
    "    - Ensure proper indentation and spacing\n",
    "</Length and style>\n",
    "\n",
    "<Quality checks>\n",
    "- Exactly 150-200 words (excluding title and sources)\n",
    "- Careful use of only ONE structural element (table or list) and only if it helps clarify your point\n",
    "- One specific example / case study\n",
    "- Starts with bold insight\n",
    "- No preamble prior to creating the section content\n",
    "- If there is a discrepancy between the existing section content and the Source material, use the existing section content as the primary source. The purpose of the Source material is to provide additional information and context to help fill the gaps in the existing section content.\n",
    "</Quality checks>\n",
    "\"\"\"\n",
    "\n",
    "# Instructions for section grading\n",
    "section_grader_instructions = \"\"\"Review a report section relative to the specified topic:\n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<section topic>\n",
    "{section_topic}\n",
    "</section topic>\n",
    "\n",
    "<section content>\n",
    "{section}\n",
    "</section content>\n",
    "\n",
    "<search type>\n",
    "{current_iteration}\n",
    "</search type>\n",
    "\n",
    "<task>\n",
    "Evaluate whether the section content adequately addresses the section topic.\n",
    "\n",
    "If the section content does not adequately address the section topic, generate {number_of_follow_up_queries} follow-up search queries to gather missing information. Note that if search type is 1, your follow-up search queries will be used to search Arxiv for academic papers. If search type is 2 or more, your follow-up search queries will be used to search Tavily for general web search.\n",
    "</task>\n",
    "\n",
    "<format>\n",
    "    grade: Literal[\"pass\",\"fail\"] = Field(\n",
    "        description=\"Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail').\"\n",
    "    )\n",
    "    follow_up_queries: List[SearchQuery] = Field(\n",
    "        description=\"List of follow-up search queries.\",\n",
    "    )\n",
    "</format>\n",
    "\"\"\"\n",
    "\n",
    "final_section_writer_instructions=\"\"\"You are an expert technical writer crafting a section that synthesizes information from the rest of the report.\n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Section name>\n",
    "{section_name}\n",
    "</Section name>\n",
    "\n",
    "<Section topic> \n",
    "{section_topic}\n",
    "</Section topic>\n",
    "\n",
    "<Available report content>\n",
    "{context}\n",
    "</Available report content>\n",
    "\n",
    "<Task>\n",
    "1. Section-Specific Approach:\n",
    "\n",
    "For Introduction:\n",
    "- Use # for report title (Markdown format)\n",
    "- 50-100 word limit\n",
    "- Write in simple and clear language\n",
    "- Focus on the core motivation for the report in 1-2 paragraphs\n",
    "- Use a clear narrative arc to introduce the report\n",
    "- Include NO structural elements (no lists or tables)\n",
    "- No sources section needed\n",
    "\n",
    "For Conclusion/Summary:\n",
    "- Use ## for section title (Markdown format)\n",
    "- 100-150 word limit\n",
    "- For comparative reports:\n",
    "    * Must include a focused comparison table using Markdown table syntax\n",
    "    * Table should distill insights from the report\n",
    "    * Keep table entries clear and concise\n",
    "- For non-comparative reports: \n",
    "    * Only use ONE structural element IF it helps distill the points made in the report:\n",
    "    * Either a focused table comparing items present in the report (using Markdown table syntax)\n",
    "    * Or a short list using proper Markdown list syntax:\n",
    "      - Use `*` or `-` for unordered lists\n",
    "      - Use `1.` for ordered lists\n",
    "      - Ensure proper indentation and spacing\n",
    "- End with specific next steps or implications\n",
    "- No sources section needed\n",
    "\n",
    "3. Writing Approach:\n",
    "- Use concrete details over general statements\n",
    "- Make every word count\n",
    "- Focus on your single most important point\n",
    "</Task>\n",
    "\n",
    "<Quality Checks>\n",
    "- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section\n",
    "- For conclusion: 100-150 word limit, ## for section title, only ONE structural element at most, no sources section\n",
    "- Markdown format\n",
    "- Do not include word count or any preamble in your response\n",
    "</Quality Checks>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes for Our Graph\n",
    "\n",
    "## 1. `generate_report_plan`\n",
    "\n",
    "**Purpose:**  \n",
    "Creates the initial report plan by breaking down the topic into sections and generating search queries to guide further research.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Input Extraction:** Retrieves the topic and any feedback provided.\n",
    "- **Configuration Loading:** Loads settings (e.g., report structure, number of queries, search API details).\n",
    "- **Query Generation:** Uses a writer model to generate search queries based on the topic and desired report organization.\n",
    "- **Web Search:** Executes a web search (via APIs like *tavily* or *arxiv*) with the generated queries to retrieve relevant sources.\n",
    "- **Section Planning:** Uses a planner model to create detailed sections (each with a name, description, plan, research flag, and content field) based on the gathered sources.\n",
    "- **Output:** Returns a dictionary with a key `\"sections\"` containing a list of planned sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "# Nodes\n",
    "async def generate_report_plan(state: ReportState, config: RunnableConfig):\n",
    "    \"\"\" Generate the report plan \"\"\"\n",
    "\n",
    "    # Inputs\n",
    "    topic = state[\"topic\"]\n",
    "    feedback = state.get(\"feedback_on_report_plan\", None)\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    report_structure = configurable.report_structure\n",
    "    number_of_queries = configurable.number_of_queries\n",
    "    # We want to use tavily as the search API for generating the report plan\n",
    "    search_api = \"tavily\"\n",
    "    \n",
    "\n",
    "    # Convert JSON object to string if necessary\n",
    "    if isinstance(report_structure, dict):\n",
    "        report_structure = str(report_structure)\n",
    "\n",
    "    # Set writer model (model used for query writing and section writing)\n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider) \n",
    "\n",
    "    # Forces the model to generate valid JSON matching the Queries schema, which \n",
    "    # makes it easier to process the results systemically\n",
    "    structured_llm = writer_model.with_structured_output(Queries)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions_query = report_planner_query_writer_instructions.format(topic=topic, report_organization=report_structure, number_of_queries=number_of_queries)\n",
    "\n",
    "    # Generate queries  \n",
    "    results = structured_llm.invoke([SystemMessage(content=system_instructions_query),\n",
    "                                     HumanMessage(content=\"Generate search queries that will help with planning the sections of the report.\")])\n",
    "\n",
    "    # Web search\n",
    "    query_list = [query.search_query for query in results.queries]\n",
    "\n",
    "    search_api_config = configurable.search_api_config or {}\n",
    "    params_to_pass = get_search_params(search_api, search_api_config)\n",
    "\n",
    "    # Search the web with parameters\n",
    "    if search_api == \"tavily\":\n",
    "        search_results = await tavily_search_async(query_list, **params_to_pass)\n",
    "        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=False)\n",
    "    elif search_api == \"arxiv\":\n",
    "        search_results = await arxiv_search_async(query_list, **params_to_pass)\n",
    "        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search API: {search_api}\")\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=report_structure, context=source_str, feedback=feedback)\n",
    "\n",
    "    # Set the planner\n",
    "    planner_provider = get_config_value(configurable.planner_provider)\n",
    "    planner_model = get_config_value(configurable.planner_model)\n",
    "\n",
    "    # Report planner instructions\n",
    "    planner_message = \"\"\"Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. \n",
    "                        Each section must have: name, description, plan, research, and content fields.\"\"\"\n",
    "\n",
    "    # Run the planner\n",
    "\n",
    "    planner_llm = init_chat_model(\n",
    "    model=planner_model,  \n",
    "    model_provider=planner_provider,\n",
    "    max_tokens=32_000,  \n",
    "    thinking={\"type\": \"enabled\", \"budget_tokens\": 24_000}  \n",
    "    )\n",
    "\n",
    "    # Forces the model to generate valid JSON matching the Sections schema, which \n",
    "    # makes it easier to process the results systemically\n",
    "    structured_llm = planner_llm.with_structured_output(Sections)\n",
    "    report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections),\n",
    "                                                 HumanMessage(content=planner_message)])\n",
    "\n",
    "    # Get sections\n",
    "    sections = report_sections.sections\n",
    "\n",
    "    return {\"sections\": sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `human_feedback`\n",
    "\n",
    "**Purpose:**  \n",
    "Obtains user feedback on the generated report plan and decides whether to approve the plan or refine it.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Plan Formatting:** Converts the planned sections into a readable string format.\n",
    "- **Feedback Collection:** Uses an interrupt (user prompt) to gather approval or suggestions.\n",
    "- **Decision Making:**  \n",
    "  - If approved (feedback is `True`), triggers the building of report sections that require further research.  \n",
    "  - If not, updates the report plan with the provided feedback and regenerates the plan.\n",
    "- **Output:** Returns a command directing the next step—either to build sections or to re-run the planning node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state: ReportState, config: RunnableConfig) -> Command[Literal[\"generate_report_plan\",\"build_section_with_web_research\"]]:\n",
    "    \"\"\" Get feedback on the report plan \"\"\"\n",
    "\n",
    "    # Get sections\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state['sections']\n",
    "    sections_str = \"\\n\\n\".join(\n",
    "        f\"Section: {section.name}\\n\"\n",
    "        f\"Description: {section.description}\\n\"\n",
    "        f\"Research needed: {'Yes' if section.research else 'No'}\\n\"\n",
    "        for section in sections\n",
    "    )\n",
    "\n",
    "    # Get feedback on the report plan from interrupt\n",
    "    interrupt_message = f\"\"\"Please provide feedback on the following report plan. \n",
    "                        \\n\\n{sections_str}\\n\\n\n",
    "                        \\nDoes the report plan meet your needs? Pass 'true' without the single quotes to approve the report plan or provide feedback to regenerate the report plan:\"\"\"\n",
    "    \n",
    "    feedback = interrupt(interrupt_message)\n",
    "\n",
    "    # If the user approves the report plan, kick off section writing\n",
    "    if isinstance(feedback, bool) and feedback is True:\n",
    "        # Treat this as approve and kick off section writing\n",
    "        # Command(goto=[]) is powerful because it dynamically creates multiple parallel \n",
    "        # execution branches - one for each section that requires research\n",
    "        return Command(goto=[\n",
    "            Send(\"build_section_with_web_research\", {\"topic\": topic, \"section\": s, \"search_iterations\": 0}) \n",
    "            for s in sections \n",
    "            if s.research\n",
    "        ])\n",
    "    \n",
    "    # If the user provides feedback, regenerate the report plan \n",
    "    elif isinstance(feedback, str):\n",
    "        # Treat this as feedback\n",
    "        return Command(goto=\"generate_report_plan\", \n",
    "                       update={\"feedback_on_report_plan\": feedback})\n",
    "    else:\n",
    "        raise TypeError(f\"Interrupt value of type {type(feedback)} is not supported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `generate_queries`\n",
    "\n",
    "**Purpose:**  \n",
    "Generates targeted search queries for a specific report section to drive focused web research.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Input Extraction:** Uses the topic and section description.\n",
    "- **Query Generation:** Utilizes a writer model to generate a set number of search queries tailored to the section.\n",
    "- **Output:** Returns a dictionary with `\"search_queries\"` containing the list of generated queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\" Generate search queries for a report section to query our A/B testing RAG collection \"\"\"\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    number_of_queries = configurable.number_of_queries\n",
    "\n",
    "    # Generate queries \n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider) \n",
    "    structured_llm = writer_model.with_structured_output(Queries)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions = query_writer_instructions.format(topic=topic, \n",
    "                                                           section_topic=section.description, \n",
    "                                                           number_of_queries=number_of_queries)\n",
    "\n",
    "    # Generate queries  \n",
    "    queries = structured_llm.invoke([SystemMessage(content=system_instructions),\n",
    "                                     HumanMessage(content=\"Generate search queries on the provided topic.\")])\n",
    "\n",
    "    return {\"search_queries\": queries.queries}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `search_rag_and_web`\n",
    "\n",
    "**Purpose:**  \n",
    "Performs RAG and web searches using the generated queries to gather raw sources and relevant information for a report section.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Query List Preparation:** Converts the generated queries into a list.\n",
    "- **API Selection & Execution:** Calls the configured search API (e.g., *tavily*, etc.) with the appropriate parameters. Note that 1st search iteration we use our Kohavi RAG collection, 2nd search iteratin we use arxiv, and 3rd and final search iteration we use tavily (general web search).\n",
    "- **Result Processing:** Deduplicates and formats the search results into a single string.\n",
    "- **Iteration Update:** Increments the search iteration count for tracking.\n",
    "- **Output:** Returns a dictionary with:\n",
    "  - `\"source_str\"`: The formatted search result string.\n",
    "  - `\"source_str_all\"`: All sources for displaying to the user\n",
    "  - `\"search_iterations\"`: The updated count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_rag_and_web(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\" Search A/B testing RAG collection and web with dual source tracking \"\"\"\n",
    "\n",
    "    # Get state \n",
    "    search_queries = state[\"search_queries\"]\n",
    "    search_iterations = state[\"search_iterations\"]\n",
    "    existing_source_str_all = state.get(\"source_str_all\", \"\")  # All previous sources\n",
    "\n",
    "    # Get configuration and choose search API based on iteration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    if search_iterations == 0:\n",
    "        search_api = \"rag\"\n",
    "    elif search_iterations == 1:\n",
    "        search_api = \"arxiv\"\n",
    "    else:\n",
    "        search_api = \"tavily\"\n",
    "\n",
    "    # Execute search \n",
    "    query_list = [query.search_query for query in search_queries]\n",
    "    search_api_config = configurable.search_api_config or {}\n",
    "    params_to_pass = get_search_params(search_api, search_api_config)\n",
    "\n",
    "    if search_api == \"rag\":\n",
    "        search_results = await rag_search_async(query_list)\n",
    "    elif search_api == \"arxiv\":\n",
    "        search_results = await arxiv_search_async(query_list, **params_to_pass)\n",
    "    elif search_api == \"tavily\":\n",
    "        search_results = await tavily_search_async(query_list)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search API: {search_api}\")\n",
    "\n",
    "    # Format current iteration sources and check if there are any\n",
    "    # Use return_has_sources=True to get both the formatted string and the boolean\n",
    "    current_source_str, has_sources = deduplicate_and_format_sources(\n",
    "        search_results, \n",
    "        max_tokens_per_source=1000, \n",
    "        include_raw_content=True, \n",
    "        search_iterations=search_iterations,\n",
    "        return_has_sources=True\n",
    "    )\n",
    "\n",
    "    # Only add iteration header and sources if there are actually sources to display\n",
    "    if has_sources:\n",
    "        iteration_header = f\"{'='*80}\\nSEARCH ITERATION {search_iterations + 1} - {search_api.upper()} RESULTS\\n{'='*80}\\n\\n\"\n",
    "        \n",
    "        # Accumulate all sources for user display\n",
    "        if existing_source_str_all:\n",
    "            accumulated_source_str = existing_source_str_all + \"\\n\\n\" + iteration_header + current_source_str\n",
    "        else:\n",
    "            accumulated_source_str = iteration_header + current_source_str\n",
    "    else:\n",
    "        # No sources found, don't add header, keep existing sources\n",
    "        accumulated_source_str = existing_source_str_all\n",
    "        current_source_str = \"\"  # No sources for writer\n",
    "\n",
    "    return {\n",
    "        \"source_str\": current_source_str,  # Only current iteration for writer\n",
    "        \"source_str_all\": accumulated_source_str,  # All sources for user display\n",
    "        \"search_iterations\": search_iterations + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. `write_section`\n",
    "\n",
    "**Purpose:**  \n",
    "Writes the content of a report section by synthesizing the gathered RAG/web research.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Content Generation:** Uses a writer model to create section content based on the topic, section details, and the context provided by the search results.\n",
    "- **Content Validation:**  \n",
    "  - Employs a planner model to grade the generated section.  \n",
    "  - Determines if additional research is needed (by checking the grade or if the maximum search iterations are reached).\n",
    "- **Control Flow:**  \n",
    "  - If the section passes or maximum iterations are reached, it publishes the section to completed sections.  \n",
    "  - Otherwise, it updates the section with follow-up queries (specific to the search tool used for that iteration round) and loops back to `search_rag_and_web`.\n",
    "- **Output:** Returns a command that either ends the search for this section or directs the next web search iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_section(state: SectionState, config: RunnableConfig) -> Command[Literal[END, \"search_rag_and_web\"]]:\n",
    "    \"\"\" Write a section of the report \"\"\"\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "    source_str = state[\"source_str\"]\n",
    "    search_iterations = state[\"search_iterations\"]  \n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions = section_writer_instructions.format(topic=topic, \n",
    "                                                             section_name=section.name, \n",
    "                                                             section_topic=section.description, \n",
    "                                                             context=source_str, \n",
    "                                                             section_content=section.content)\n",
    "    \n",
    "    # Generate section  \n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider) \n",
    "    section_content = writer_model.invoke([SystemMessage(content=system_instructions),\n",
    "                                           HumanMessage(content=\"Generate a report section based on the existing section content (if any) and the provided sources.\")])\n",
    "    \n",
    "    # Write content to the section object  \n",
    "    section.content = section_content.content\n",
    "\n",
    "    # Grade prompt \n",
    "    section_grader_message = \"\"\"Grade the report and consider follow-up questions for missing information.\n",
    "                               If the grade is 'pass', return empty strings for all follow-up queries.\n",
    "                               If the grade is 'fail', provide specific search queries to gather missing information.\"\"\"\n",
    "    \n",
    "    section_grader_instructions_formatted = section_grader_instructions.format(topic=topic, \n",
    "                                                                               section_topic=section.description,\n",
    "                                                                               section=section.content, \n",
    "                                                                               number_of_follow_up_queries=configurable.number_of_queries,\n",
    "                                                                               current_iteration=search_iterations)\n",
    "    \n",
    "    # Use planner model for reflection\n",
    "    planner_provider = get_config_value(configurable.planner_provider)\n",
    "    planner_model = get_config_value(configurable.planner_model)\n",
    "\n",
    "    reflection_llm = init_chat_model(\n",
    "    model=planner_model,  \n",
    "    model_provider=planner_provider,\n",
    "    max_tokens=32_000,  \n",
    "    thinking={\"type\": \"enabled\", \"budget_tokens\": 24_000}  \n",
    "    )\n",
    "\n",
    "    reflection_model = reflection_llm.with_structured_output(Feedback)\n",
    "    feedback = reflection_model.invoke([SystemMessage(content=section_grader_instructions_formatted),\n",
    "                                            HumanMessage(content=section_grader_message)])\n",
    "    \n",
    "    # If the section is passing or max depth reached\n",
    "    if feedback.grade == \"pass\" or state[\"search_iterations\"] >= configurable.max_search_depth:\n",
    "        # Store sources in the section object \n",
    "        section.sources = state.get(\"source_str_all\", \"\") \n",
    "\n",
    "        return Command(\n",
    "            update={\n",
    "                \"completed_sections\": [section]\n",
    "            },\n",
    "            goto=END\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            update={\"search_queries\": feedback.follow_up_queries, \"section\": section},\n",
    "            goto=\"search_rag_and_web\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. `write_final_sections`\n",
    "\n",
    "**Purpose:**  \n",
    "Generates the final version of sections that do not require further research by using the compiled context from completed sections.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Context Preparation:** Receives the topic, section details, and the aggregated completed sections.\n",
    "- **Final Writing:** Uses a writer model to produce the final version of the section content.\n",
    "- **Output:** Returns a dictionary with `\"completed_sections\"` updated with the final section content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_final_sections(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\" Write final sections of the report, which do not require RAG or web search and use the completed sections as context \"\"\"\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "    completed_report_sections = state[\"report_sections_from_research\"]\n",
    "    \n",
    "    # Format system instructions\n",
    "    system_instructions = final_section_writer_instructions.format(topic=topic, section_name=section.name, section_topic=section.description, context=completed_report_sections)\n",
    "\n",
    "    # Generate section  \n",
    "    writer_provider = get_config_value(configurable.writer_provider)\n",
    "    writer_model_name = get_config_value(configurable.writer_model)\n",
    "    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider) \n",
    "    section_content = writer_model.invoke([SystemMessage(content=system_instructions),\n",
    "                                           HumanMessage(content=\"Generate a report section based on the provided sources.\")])\n",
    "    \n",
    "    # Write content to section \n",
    "    section.content = section_content.content\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. `gather_completed_sections`\n",
    "\n",
    "**Purpose:**  \n",
    "Consolidates all completed sections (in the right order!) into a formatted context string to support final section writing.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Aggregation:** Collates completed sections from earlier research in the right order.\n",
    "- **Formatting:** Converts each section into a string format to be used as context. We make sure to remove sources since we don't need them for writing the final sections (would just clog up the context window).\n",
    "- **Output:** Returns a dictionary with `\"report_sections_from_research\"` containing the aggregated context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_completed_sections(state: ReportState):\n",
    "    \"\"\" Gather completed sections from research and format them as context for writing the final sections \"\"\"    \n",
    "\n",
    "    # Get original section order and completed sections\n",
    "    original_sections = state[\"sections\"]\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "    \n",
    "    # Create mapping of completed sections by name\n",
    "    completed_by_name = {s.name: s for s in completed_sections}\n",
    "    \n",
    "    # Sort completed sections by original report order\n",
    "    ordered_completed_sections = []\n",
    "    for original_section in original_sections:\n",
    "        if original_section.name in completed_by_name:\n",
    "            ordered_completed_sections.append(completed_by_name[original_section.name])\n",
    "    \n",
    "    # Create sections without sources in correct order\n",
    "    sections_without_sources = []\n",
    "    for section in ordered_completed_sections:\n",
    "        temp_section = Section(\n",
    "            name=section.name,\n",
    "            description=section.description,\n",
    "            research=section.research,\n",
    "            content=section.content,\n",
    "            sources=\"\"\n",
    "        )\n",
    "        sections_without_sources.append(temp_section)\n",
    "\n",
    "    # Format in original report order\n",
    "    completed_report_sections = format_sections(sections_without_sources)\n",
    "\n",
    "    return {\"report_sections_from_research\": completed_report_sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. `initiate_final_section_writing`\n",
    "\n",
    "**Purpose:**  \n",
    "Triggers the final writing phase for report sections that do not need further web research.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Selection:** Identifies sections marked as not requiring additional research.\n",
    "- **Parallel Processing:** Uses a parallelized `Send()` API to launch final section writing tasks concurrently.\n",
    "- **Output:** Returns a list of `Send` commands for writing final sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_final_section_writing(state: ReportState):\n",
    "    \"\"\" Write any final sections using the Send API to parallelize the process \"\"\"    \n",
    "\n",
    "    # Kick off section writing in parallel via Send() API for any sections that do not require research\n",
    "    return [\n",
    "        Send(\"write_final_sections\", {\"topic\": state[\"topic\"], \"section\": s, \"report_sections_from_research\": state[\"report_sections_from_research\"]}) \n",
    "        for s in state[\"sections\"] \n",
    "        if not s.research # only sections that do not require research (e.g. intro and conclusion)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. `compile_final_report`\n",
    "\n",
    "**Purpose:**  \n",
    "Compiles all finalized sections into one cohesive final report.\n",
    "\n",
    "**Key Steps:**\n",
    "- **Content Mapping:** Matches the finalized content with the original sections while preserving the intended order.\n",
    "- **Report Assembly:** Joins all section contents together into a single text string.\n",
    "- **Sources Assembly:** Handles proper output of all the sources to be displayed to the user.\n",
    "- **Output:** Returns a dictionary with the key `\"final_report\"` containing the complete report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_final_report(state: ReportState):\n",
    "    \"\"\" Compile the final report with section-grouped sources only for research sections \"\"\"    \n",
    "\n",
    "    # Get sections and sources\n",
    "    sections = state[\"sections\"]\n",
    "    completed_sections = {s.name: s.content for s in state[\"completed_sections\"]}\n",
    "\n",
    "    # Update sections with completed content while maintaining original order\n",
    "    for section in sections:\n",
    "        section.content = completed_sections[section.name]\n",
    "\n",
    "    # Compile main report\n",
    "    main_report = \"\\n\\n\".join([s.content for s in sections])\n",
    "    \n",
    "    # Add sources section with organization by research sections only\n",
    "    research_sections_with_sources = [s for s in state[\"completed_sections\"] if s.research and s.sources]\n",
    "    \n",
    "    if research_sections_with_sources:\n",
    "        sources_section = \"\\n\\n## Sources Used\\n\\n\"\n",
    "        \n",
    "        # Iterate through sections in original order and add sources if they exist\n",
    "        for section in sections:\n",
    "            if section.research:\n",
    "                # Find the completed section with sources\n",
    "                completed_section = next((s for s in state[\"completed_sections\"] if s.name == section.name), None)\n",
    "                if completed_section and completed_section.sources:\n",
    "                    sources_section += f\"### Sources for Section: {section.name}\\n\\n\"\n",
    "                    sources_section += completed_section.sources + \"\\n\\n\"\n",
    "        \n",
    "        final_report_with_sources = main_report + sources_section\n",
    "    else:\n",
    "        final_report_with_sources = main_report\n",
    "\n",
    "    return {\"final_report\": final_report_with_sources}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD THAT GRAPH!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x175bdfce0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_builder = StateGraph(SectionState, output=SectionOutputState)\n",
    "section_builder.add_node(\"generate_queries\", generate_queries)\n",
    "section_builder.add_node(\"search_rag_and_web\", search_rag_and_web)\n",
    "section_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# Add edges\n",
    "section_builder.add_edge(START, \"generate_queries\")\n",
    "section_builder.add_edge(\"generate_queries\", \"search_rag_and_web\")\n",
    "section_builder.add_edge(\"search_rag_and_web\", \"write_section\")\n",
    "\n",
    "# Outer graph -- \n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)\n",
    "builder.add_node(\"generate_report_plan\", generate_report_plan)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"build_section_with_web_research\", section_builder.compile())\n",
    "builder.add_node(\"gather_completed_sections\", gather_completed_sections)\n",
    "builder.add_node(\"write_final_sections\", write_final_sections)\n",
    "builder.add_node(\"compile_final_report\", compile_final_report)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"generate_report_plan\")\n",
    "builder.add_edge(\"generate_report_plan\", \"human_feedback\")\n",
    "builder.add_edge(\"build_section_with_web_research\", \"gather_completed_sections\")\n",
    "builder.add_conditional_edges(\"gather_completed_sections\", initiate_final_section_writing, [\"write_final_sections\"])\n",
    "builder.add_edge(\"write_final_sections\", \"compile_final_report\")\n",
    "builder.add_edge(\"compile_final_report\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Graph: WITH CHECKPOINTS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Without checkpointing, any interactive elements (e.g. user feedback) would require \n",
    "# restarting the entire graph from scratch.\n",
    "# Create a memory saver for checkpointing\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer\n",
    "graph_with_checkpoint = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_report_plan': {'sections': [Section(name='Introduction to Group Sequential Testing', description='Overview of group sequential testing methodology, its purpose in clinical trials, and advantages over traditional fixed-sample designs. Covers the fundamental concept of interim analyses and early stopping decisions.', research=False, content='', sources=''), Section(name='Statistical Framework and Stopping Boundaries', description=\"Core statistical principles underlying group sequential designs, including alpha spending functions, types of stopping boundaries (Pocock, O'Brien-Fleming, Wang-Tsiatis), and methods for controlling Type I error rates across multiple analyses.\", research=True, content='', sources=''), Section(name='Types of Group Sequential Designs and Applications', description='Comprehensive overview of different group sequential design approaches including classical designs, adaptive designs, and hybrid approaches. Covers selection criteria, advantages and limitations of each type, with practical examples from clinical trials.', research=True, content='', sources=''), Section(name='Implementation Considerations and Regulatory Guidance', description='Practical aspects of implementing group sequential designs in clinical trials, including sample size calculations, software tools, data monitoring committee operations, and regulatory perspectives from FDA and other agencies. Includes best practices for design specification and execution.', research=True, content='', sources=''), Section(name='Conclusion and Key Takeaways', description='Summary of group sequential testing benefits and challenges, featuring a comparison table of major design types. Includes a comprehensive paragraph (under 500 words) synthesizing the key takeaways and future directions in group sequential methodology.', research=False, content='', sources='')]}}\n",
      "\n",
      "\n",
      "{'__interrupt__': (Interrupt(value=\"Please provide feedback on the following report plan. \\n                        \\n\\nSection: Introduction to Group Sequential Testing\\nDescription: Overview of group sequential testing methodology, its purpose in clinical trials, and advantages over traditional fixed-sample designs. Covers the fundamental concept of interim analyses and early stopping decisions.\\nResearch needed: No\\n\\n\\nSection: Statistical Framework and Stopping Boundaries\\nDescription: Core statistical principles underlying group sequential designs, including alpha spending functions, types of stopping boundaries (Pocock, O'Brien-Fleming, Wang-Tsiatis), and methods for controlling Type I error rates across multiple analyses.\\nResearch needed: Yes\\n\\n\\nSection: Types of Group Sequential Designs and Applications\\nDescription: Comprehensive overview of different group sequential design approaches including classical designs, adaptive designs, and hybrid approaches. Covers selection criteria, advantages and limitations of each type, with practical examples from clinical trials.\\nResearch needed: Yes\\n\\n\\nSection: Implementation Considerations and Regulatory Guidance\\nDescription: Practical aspects of implementing group sequential designs in clinical trials, including sample size calculations, software tools, data monitoring committee operations, and regulatory perspectives from FDA and other agencies. Includes best practices for design specification and execution.\\nResearch needed: Yes\\n\\n\\nSection: Conclusion and Key Takeaways\\nDescription: Summary of group sequential testing benefits and challenges, featuring a comparison table of major design types. Includes a comprehensive paragraph (under 500 words) synthesizing the key takeaways and future directions in group sequential methodology.\\nResearch needed: No\\n\\n\\n\\n                        \\nDoes the report plan meet your needs? Pass 'true' without the single quotes to approve the report plan or provide feedback to regenerate the report plan:\", resumable=True, ns=['human_feedback:580539e6-a999-ad58-09bb-2a73edda7dce']),)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Feedback Request:**\n",
       "Please provide feedback on the following report plan. \n",
       "                        \n",
       "\n",
       "Section: Introduction to Group Sequential Testing\n",
       "Description: Overview of group sequential testing methodology, its purpose in clinical trials, and advantages over traditional fixed-sample designs. Covers the fundamental concept of interim analyses and early stopping decisions.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: Statistical Framework and Stopping Boundaries\n",
       "Description: Core statistical principles underlying group sequential designs, including alpha spending functions, types of stopping boundaries (Pocock, O'Brien-Fleming, Wang-Tsiatis), and methods for controlling Type I error rates across multiple analyses.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Types of Group Sequential Designs and Applications\n",
       "Description: Comprehensive overview of different group sequential design approaches including classical designs, adaptive designs, and hybrid approaches. Covers selection criteria, advantages and limitations of each type, with practical examples from clinical trials.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Implementation Considerations and Regulatory Guidance\n",
       "Description: Practical aspects of implementing group sequential designs in clinical trials, including sample size calculations, software tools, data monitoring committee operations, and regulatory perspectives from FDA and other agencies. Includes best practices for design specification and execution.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Conclusion and Key Takeaways\n",
       "Description: Summary of group sequential testing benefits and challenges, featuring a comparison table of major design types. Includes a comprehensive paragraph (under 500 words) synthesizing the key takeaways and future directions in group sequential methodology.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "\n",
       "                        \n",
       "Does the report plan meet your needs? Pass 'true' without the single quotes to approve the report plan or provide feedback to regenerate the report plan:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a unique thread ID to identify the specific graph execution for checkpointing\n",
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "# Start the graph execution with the topic and display the final report when it appears\n",
    "async def run_graph_and_show_report():\n",
    "    \"\"\"Run the graph and display the final report when it appears\"\"\"\n",
    "    async for chunk in graph_with_checkpoint.astream(\n",
    "        {\"topic\": \"Group Sequential Testing\"}, \n",
    "        {\"configurable\": {\"thread_id\": thread_id}},\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        print(chunk)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Check if this chunk contains the final_report\n",
    "        if isinstance(chunk, dict) and 'final_report' in chunk:\n",
    "            print(\"🎉 Final report generated! 🎉\")\n",
    "            display(Markdown(f\"# Group Sequential Testing Report\\n\\n{chunk['final_report']}\"))\n",
    "            return\n",
    "        \n",
    "        # Check if this is an interrupt that needs user feedback\n",
    "        if isinstance(chunk, dict) and '__interrupt__' in chunk:\n",
    "            interrupt_value = chunk['__interrupt__'][0].value\n",
    "            display(Markdown(f\"**Feedback Request:**\\n{interrupt_value}\"))\n",
    "            return  # Stop execution to allow user to provide feedback\n",
    "\n",
    "# Run the graph\n",
    "await run_graph_and_show_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def approve_plan():\n",
    "    \"\"\"Approve the plan and continue execution\"\"\"\n",
    "    async for chunk in graph_with_checkpoint.astream(\n",
    "        Command(resume=True), \n",
    "        {\"configurable\": {\"thread_id\": thread_id}},\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        print(chunk)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Check if this chunk contains the compile_final_report with final_report\n",
    "        if isinstance(chunk, dict) and 'compile_final_report' in chunk:\n",
    "            if 'final_report' in chunk['compile_final_report']:\n",
    "                print(\"🎉 Final report generated! 🎉\")\n",
    "                final_report = chunk['compile_final_report']['final_report']\n",
    "                display(Markdown(f\"# Group Sequential Testing Report\\n\\n{final_report}\"))\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def provide_feedback(feedback_text):\n",
    "    \"\"\"Provide feedback and continue execution\"\"\"\n",
    "    async for chunk in graph_with_checkpoint.astream(\n",
    "        Command(resume=feedback_text), \n",
    "        {\"configurable\": {\"thread_id\": thread_id}},\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        print(chunk)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Check if this chunk contains the final_report\n",
    "        if isinstance(chunk, dict) and 'final_report' in chunk:\n",
    "            print(\"🎉 Final report generated! 🎉\")\n",
    "            display(Markdown(f\"# Group Sequential Testing Report\\n\\n{chunk['final_report']}\"))\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: You *can* choose to continue the flow - though the notebook implementation will require you to stretch your coding muscles a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_feedback': None}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n",
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n",
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n",
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n",
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No raw_content found for source https://pmc.ncbi.nlm.nih.gov/articles/PMC10260346/\n",
      "Warning: No raw_content found for source https://jamanetwork.com/journals/jama/fullarticle/2784821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No raw_content found for source https://www.sciencedirect.com/science/article/pii/S2451865418300097\n",
      "Warning: No raw_content found for source https://pmc.ncbi.nlm.nih.gov/articles/PMC4024106/\n",
      "Warning: No raw_content found for source https://www.biostat.wisc.edu/~chappell/641/papers/paper35.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n",
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Types of Group Sequential Designs and Applications', description='Comprehensive overview of different group sequential design approaches including classical designs, adaptive designs, and hybrid approaches. Covers selection criteria, advantages and limitations of each type, with practical examples from clinical trials.', research=True, content=\"## Types of Group Sequential Designs and Applications\\n\\n**Group sequential designs have evolved from simple two-arm comparisons to sophisticated multi-stage frameworks that accommodate complex trial architectures while maintaining statistical rigor.**\\n\\nClassical designs form the foundation with well-established boundary functions. O'Brien-Fleming boundaries provide conservative early stopping with α-spending concentrated at final analysis, making them ideal for confirmatory trials requiring high evidence standards. Pocock boundaries distribute α equally across analyses, offering simpler implementation but demanding larger sample sizes.\\n\\nAdaptive designs enable protocol modifications based on accumulating data. Sample size re-estimation addresses initial planning uncertainties, while population enrichment focuses recruitment on responsive subgroups. These designs require careful pre-specification to maintain statistical validity.\\n\\nPlatform trials represent the most complex application, allowing multiple treatments to enter and exit dynamically. They require sophisticated multiple comparison procedures and online error rate control as demonstrated in COVID-19 vaccine trials where treatments were added sequentially.\\n\\nHybrid approaches combine fixed and adaptive elements, balancing operational flexibility with regulatory acceptance. The choice depends on study objectives, regulatory pathway, and institutional capacity for complex interim decision-making.\\n\\n| Design Type | Boundary Characteristic | Optimal Application |\\n|-------------|------------------------|-------------------|\\n| O'Brien-Fleming | Conservative early, liberal late | Confirmatory trials |\\n| Pocock | Constant across analyses | Exploratory studies |\\n| Adaptive | Data-driven modifications | Uncertain populations |\", sources=\"================================================================================\\nSEARCH ITERATION 1 - RAG RESULTS\\n================================================================================\\n\\nKohavi: Online Controlled Experiments and AB Tests, Section: Increasing Experiment Sensitivity\\n===\\nKohavi: Online Controlled Experiments and AB Tests, Section: Sample size.\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: Abstract\\n===\\nKohavi: Online Controlled Experiments at Large Scale, Section: 3.1 Why Controlled Experiments?\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 3.6 Limitations\\n===\\n\\n================================================================================\\nSEARCH ITERATION 2 - ARXIV RESULTS\\n================================================================================\\n\\nInterim Monitoring of Sequential Multiple Assignment Randomized Trials Using Partial Information\\n===\\nURL: http://arxiv.org/abs/2209.06306v2\\n===\\nInterim Analysis in Sequential Multiple Assignment Randomized Trials for Survival Outcomes\\n===\\nURL: http://arxiv.org/abs/2504.03143v1\\n===\\nOnline control of the False Discovery Rate in group-sequential platform trials\\n===\\nURL: http://arxiv.org/abs/2112.10619v1\\n===\\n\\n================================================================================\\nSEARCH ITERATION 3 - TAVILY RESULTS\\n================================================================================\\n\\nPDF\\n===\\nURL: https://mwsug.org/proceedings/2016/PH/MWSUG-2016-PH06.pdf\\n===\\nFull source content limited to 1000 tokens \\n\\n6 Deriving group sequential designs - gsDesign Technical Manual\\n===\\nURL: https://keaven.github.io/gsd-tech-manual/gsdesign.html\\n===\\nFull source content limited to 1000 tokens \\n\\nGuidance on interim analysis methods in clinical trials - PMC\\n===\\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC10260346/\\n===\\n9.5 - Frequentist Methods: O'Brien-Fleming, Pocock, Haybittle-Peto\\n===\\nURL: https://online.stat.psu.edu/stat509/lesson/9/9.5\\n===\\nFull source content limited to 1000 tokens \\n\\nInterim Analyses During Group Sequential Clinical Trials\\n===\\nURL: https://jamanetwork.com/journals/jama/fullarticle/2784821\\n===\")]}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Statistical Framework and Stopping Boundaries', description=\"Core statistical principles underlying group sequential designs, including alpha spending functions, types of stopping boundaries (Pocock, O'Brien-Fleming, Wang-Tsiatis), and methods for controlling Type I error rates across multiple analyses.\", research=True, content=\"## Statistical Framework and Stopping Boundaries\\n\\n**Group sequential testing requires careful balance between early stopping opportunities and Type I error control through mathematically rigorous boundary frameworks that extend beyond traditional efficacy-only designs.**\\n\\nAlpha spending functions provide the foundation for controlling overall significance levels across multiple interim analyses. The Lan-DeMets approach allows flexible timing of analyses by specifying how the total Type I error rate (typically 0.05) is allocated across planned looks, ensuring statistical validity regardless of when stopping occurs.\\n\\nInformation fractions define the proportion of total planned information available at each interim analysis. These fractions drive boundary calculations and must account for missing data patterns and endpoint-specific accumulation rates.\\n\\nThree primary boundary types dominate practice:\\n\\n* **Pocock boundaries** maintain constant critical values across all analyses, enabling easier interpretation but requiring larger sample sizes\\n* **O'Brien-Fleming boundaries** use conservative early thresholds that relax toward standard levels, preserving power while allowing early efficacy detection  \\n* **Wang-Tsiatis boundaries** offer flexible parameterization between Pocock and O'Brien-Fleming extremes\\n\\nModern applications extend to changing primary endpoints mid-trial through flexible boundary adjustments. LinkedIn's experimentation platform demonstrates practical trade-offs: O'Brien-Fleming boundaries reduce false positives in early analyses but require stronger evidence for early termination.\", sources='================================================================================\\nSEARCH ITERATION 1 - RAG RESULTS\\n================================================================================\\n\\nKohavi: LinkedIn Post (New_AB_Pattern_Reproduction_Results), Section: unknown\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 3. Primacy and newness effects.\\n===\\nKohavi: LinkedIn Post (Lead_with_Clear_Memorable_Leadership_Principl), Section: unknown\\n===\\nKohavi: Why are Power Calculators Giving Different Results, Section: Untitled\\n===\\nKohavi: Online Controlled Experiments at Large Scale, Section: 4.3 Alerts and Aborting Bad Experiments\\n===\\n\\n================================================================================\\nSEARCH ITERATION 2 - ARXIV RESULTS\\n================================================================================\\n\\nExact sequential single-arm trial design with curtailment for binary endpoint\\n===\\nURL: http://arxiv.org/abs/2303.17091v1\\n===\\nInterim Analysis in Sequential Multiple Assignment Randomized Trials for Survival Outcomes\\n===\\nURL: http://arxiv.org/abs/2504.03143v1\\n===\\nBayesian response adaptive randomization design with a composite endpoint of mortality and morbidity\\n===\\nURL: http://arxiv.org/abs/2208.08472v3\\n===\\n\\n================================================================================\\nSEARCH ITERATION 3 - TAVILY RESULTS\\n================================================================================\\n\\nDefining information fractions in group sequential clinical trials with ...\\n===\\nURL: https://www.sciencedirect.com/science/article/pii/S2451865418300097\\n===\\nFlexible Stopping Boundaries When Changing Primary Endpoints after ...\\n===\\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC4024106/\\n===\\nPDF\\n===\\nURL: https://www.biostat.wisc.edu/~chappell/641/papers/paper35.pdf\\n===\\n9.6 - Alpha Spending Function approach | STAT 509 - Statistics Online\\n===\\nURL: https://online.stat.psu.edu/stat509/lesson/9/9.6\\n===\\nPDF\\n===\\nURL: https://eclass.uoa.gr/modules/document/file.php/MATH301/PracticalSession3/LanDeMets.pdf\\n===\\nFull source content limited to 1000 tokens')]}}\n",
      "\n",
      "\n",
      "Warning: No raw_content found for source https://www.sciencedirect.com/science/article/pii/S2451865418300097\n",
      "Warning: No raw_content found for source https://pmc.ncbi.nlm.nih.gov/articles/PMC3434206/\n",
      "Warning: No raw_content found for source https://jamanetwork.com/journals/jama/fullarticle/2784821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamerankolahi/AB_AI_Github/v_3_notebook/.venv/lib/python3.12/site-packages/langchain_anthropic/chat_models.py:1235: UserWarning: Anthropic structured output relies on forced tool calling, which is not supported when `thinking` is enabled. This method will raise langchain_core.exceptions.OutputParserException if tool calls are not generated. Consider disabling `thinking` or adjust your prompt to ensure the tool is called.\n",
      "  warnings.warn(thinking_admonition)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Implementation Considerations and Regulatory Guidance', description='Practical aspects of implementing group sequential designs in clinical trials, including sample size calculations, software tools, data monitoring committee operations, and regulatory perspectives from FDA and other agencies. Includes best practices for design specification and execution.', research=True, content=\"## Implementation Considerations and Regulatory Guidance\\n\\n**Information fraction calculations require careful definition of statistical information rather than simple sample size ratios, particularly when dealing with time-to-event endpoints or unequal allocation schemes.** This fundamental concept drives all subsequent implementation decisions.\\n\\nSample size calculations must account for information fractions and spending functions, with validation across multiple platforms. The alpha spending function approach provides flexible boundary construction, allowing investigators to specify spending rates at planned interim analyses without rigid pre-commitment to specific critical values.\\n\\nSoftware tools like East, PASS, and R's gsDesign package handle sequential boundaries effectively. Recent simulation methods enable practical sample size calculations by incorporating realistic assumptions about enrollment patterns, dropout rates, and effect size uncertainty.\\n\\nData monitoring committees require enhanced training on information-based stopping rules and access to updated boundary calculations at each interim analysis. The COVID-19 pandemic demonstrated how enrollment disruptions can affect information accrual timing, making flexible spending functions essential for maintaining statistical validity.\\n\\nRegulatory agencies expect comprehensive statistical analysis plans detailing interim timing rationale, alpha spending justification, and clear stopping criteria. FDA guidance emphasizes pre-specification of all sequential testing parameters and early consultation to ensure design acceptance before trial initiation.\", sources='================================================================================\\nSEARCH ITERATION 1 - RAG RESULTS\\n================================================================================\\n\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 6.2.3 Determine the minimum sample size\\n===\\nKohavi: Online Controlled Experiments at Large Scale, Section: 5.1 False Positives\\n===\\nKohavi: The Surprising Power of Online Experiments, Section: Center-of-excellence model\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 5.2 Assignment method\\n===\\nKohavi: Why are Power Calculators Giving Different Results, Section: Explaining the differences:\\n===\\n\\n================================================================================\\nSEARCH ITERATION 2 - ARXIV RESULTS\\n================================================================================\\n\\nClinical trials impacted by the COVID-19 pandemic: Adaptive designs to the rescue?\\n===\\nURL: http://arxiv.org/abs/2005.13979v1\\n===\\nConfidence intervals for adaptive trial designs II: Case study and practical guidance\\n===\\nURL: http://arxiv.org/abs/2411.08771v1\\n===\\nConfidence intervals for adaptive trial designs I: A methodological review\\n===\\nURL: http://arxiv.org/abs/2411.08495v1\\n===\\n\\n================================================================================\\nSEARCH ITERATION 3 - TAVILY RESULTS\\n================================================================================\\n\\nDefining information fractions in group sequential clinical trials with ...\\n===\\nURL: https://www.sciencedirect.com/science/article/pii/S2451865418300097\\n===\\nA Practical Simulation Method to Calculate Sample Size of Group ...\\n===\\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC3434206/\\n===\\n8 Spending functions - Group Sequential Designs Made Easy\\n===\\nURL: https://keaven.github.io/gsd-shiny/spending.html\\n===\\nFull source content limited to 1000 tokens \\n\\nInterim Analyses During Group Sequential Clinical Trials\\n===\\nURL: https://jamanetwork.com/journals/jama/fullarticle/2784821\\n===\\n9.6 - Alpha Spending Function approach | STAT 509 - Statistics Online\\n===\\nURL: https://online.stat.psu.edu/stat509/lesson/9/9.6\\n===')]}}\n",
      "\n",
      "\n",
      "{'gather_completed_sections': {'report_sections_from_research': \"\\n============================================================ # divider line of 60 equal signs\\nSection 1: Statistical Framework and Stopping Boundaries\\n============================================================ # divider line of 60 equal signs\\nDescription:\\nCore statistical principles underlying group sequential designs, including alpha spending functions, types of stopping boundaries (Pocock, O'Brien-Fleming, Wang-Tsiatis), and methods for controlling Type I error rates across multiple analyses.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Statistical Framework and Stopping Boundaries\\n\\n**Group sequential testing requires careful balance between early stopping opportunities and Type I error control through mathematically rigorous boundary frameworks that extend beyond traditional efficacy-only designs.**\\n\\nAlpha spending functions provide the foundation for controlling overall significance levels across multiple interim analyses. The Lan-DeMets approach allows flexible timing of analyses by specifying how the total Type I error rate (typically 0.05) is allocated across planned looks, ensuring statistical validity regardless of when stopping occurs.\\n\\nInformation fractions define the proportion of total planned information available at each interim analysis. These fractions drive boundary calculations and must account for missing data patterns and endpoint-specific accumulation rates.\\n\\nThree primary boundary types dominate practice:\\n\\n* **Pocock boundaries** maintain constant critical values across all analyses, enabling easier interpretation but requiring larger sample sizes\\n* **O'Brien-Fleming boundaries** use conservative early thresholds that relax toward standard levels, preserving power while allowing early efficacy detection  \\n* **Wang-Tsiatis boundaries** offer flexible parameterization between Pocock and O'Brien-Fleming extremes\\n\\nModern applications extend to changing primary endpoints mid-trial through flexible boundary adjustments. LinkedIn's experimentation platform demonstrates practical trade-offs: O'Brien-Fleming boundaries reduce false positives in early analyses but require stronger evidence for early termination.\\n\\n\\n============================================================ # divider line of 60 equal signs\\nSection 2: Types of Group Sequential Designs and Applications\\n============================================================ # divider line of 60 equal signs\\nDescription:\\nComprehensive overview of different group sequential design approaches including classical designs, adaptive designs, and hybrid approaches. Covers selection criteria, advantages and limitations of each type, with practical examples from clinical trials.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Types of Group Sequential Designs and Applications\\n\\n**Group sequential designs have evolved from simple two-arm comparisons to sophisticated multi-stage frameworks that accommodate complex trial architectures while maintaining statistical rigor.**\\n\\nClassical designs form the foundation with well-established boundary functions. O'Brien-Fleming boundaries provide conservative early stopping with α-spending concentrated at final analysis, making them ideal for confirmatory trials requiring high evidence standards. Pocock boundaries distribute α equally across analyses, offering simpler implementation but demanding larger sample sizes.\\n\\nAdaptive designs enable protocol modifications based on accumulating data. Sample size re-estimation addresses initial planning uncertainties, while population enrichment focuses recruitment on responsive subgroups. These designs require careful pre-specification to maintain statistical validity.\\n\\nPlatform trials represent the most complex application, allowing multiple treatments to enter and exit dynamically. They require sophisticated multiple comparison procedures and online error rate control as demonstrated in COVID-19 vaccine trials where treatments were added sequentially.\\n\\nHybrid approaches combine fixed and adaptive elements, balancing operational flexibility with regulatory acceptance. The choice depends on study objectives, regulatory pathway, and institutional capacity for complex interim decision-making.\\n\\n| Design Type | Boundary Characteristic | Optimal Application |\\n|-------------|------------------------|-------------------|\\n| O'Brien-Fleming | Conservative early, liberal late | Confirmatory trials |\\n| Pocock | Constant across analyses | Exploratory studies |\\n| Adaptive | Data-driven modifications | Uncertain populations |\\n\\n\\n============================================================ # divider line of 60 equal signs\\nSection 3: Implementation Considerations and Regulatory Guidance\\n============================================================ # divider line of 60 equal signs\\nDescription:\\nPractical aspects of implementing group sequential designs in clinical trials, including sample size calculations, software tools, data monitoring committee operations, and regulatory perspectives from FDA and other agencies. Includes best practices for design specification and execution.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Implementation Considerations and Regulatory Guidance\\n\\n**Information fraction calculations require careful definition of statistical information rather than simple sample size ratios, particularly when dealing with time-to-event endpoints or unequal allocation schemes.** This fundamental concept drives all subsequent implementation decisions.\\n\\nSample size calculations must account for information fractions and spending functions, with validation across multiple platforms. The alpha spending function approach provides flexible boundary construction, allowing investigators to specify spending rates at planned interim analyses without rigid pre-commitment to specific critical values.\\n\\nSoftware tools like East, PASS, and R's gsDesign package handle sequential boundaries effectively. Recent simulation methods enable practical sample size calculations by incorporating realistic assumptions about enrollment patterns, dropout rates, and effect size uncertainty.\\n\\nData monitoring committees require enhanced training on information-based stopping rules and access to updated boundary calculations at each interim analysis. The COVID-19 pandemic demonstrated how enrollment disruptions can affect information accrual timing, making flexible spending functions essential for maintaining statistical validity.\\n\\nRegulatory agencies expect comprehensive statistical analysis plans detailing interim timing rationale, alpha spending justification, and clear stopping criteria. FDA guidance emphasizes pre-specification of all sequential testing parameters and early consultation to ensure design acceptance before trial initiation.\\n\\n\"}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Conclusion and Key Takeaways', description='Summary of group sequential testing benefits and challenges, featuring a comparison table of major design types. Includes a comprehensive paragraph (under 500 words) synthesizing the key takeaways and future directions in group sequential methodology.', research=False, content=\"## Conclusion and Key Takeaways\\n\\nGroup sequential testing offers powerful early stopping capabilities while maintaining statistical rigor, but implementation complexity varies significantly across design types. The choice between boundary approaches involves fundamental trade-offs between early detection sensitivity and sample size requirements.\\n\\n| Design Type | Primary Advantage | Key Limitation | Best Use Case |\\n|-------------|------------------|----------------|---------------|\\n| O'Brien-Fleming | Preserves power, conservative early stopping | Requires strong early evidence | Confirmatory trials |\\n| Pocock | Simple interpretation, flexible stopping | Larger sample sizes needed | Exploratory studies |\\n| Adaptive | Protocol flexibility, uncertainty handling | Complex implementation | Unknown populations |\\n| Wang-Tsiatis | Customizable boundary shapes | Parameter selection complexity | Tailored applications |\\n\\nFuture directions emphasize platform trials and real-world evidence integration, driven by pandemic-era innovations in flexible trial design. The evolution toward information-based rather than sample-based stopping criteria represents a fundamental shift requiring enhanced statistical expertise and regulatory collaboration. Success depends on pre-specification rigor, appropriate software implementation, and data monitoring committee sophistication in managing complex interim decision frameworks.\", sources='')]}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Introduction to Group Sequential Testing', description='Overview of group sequential testing methodology, its purpose in clinical trials, and advantages over traditional fixed-sample designs. Covers the fundamental concept of interim analyses and early stopping decisions.', research=False, content='# Group Sequential Testing\\n\\nGroup sequential testing revolutionizes clinical trial efficiency by enabling interim analyses with pre-planned stopping rules, offering a compelling alternative to traditional fixed-sample designs. This methodology allows trials to terminate early for efficacy, futility, or safety concerns while maintaining statistical validity through carefully constructed boundaries. By incorporating multiple planned analyses throughout the study duration, investigators can make informed decisions about continuing, modifying, or stopping trials based on accumulating evidence, potentially saving time, resources, and exposing fewer participants to ineffective treatments.\\n\\n## Summary\\n\\nGroup sequential testing has matured from simple boundary functions to sophisticated frameworks accommodating complex trial architectures. The methodology balances early stopping opportunities against Type I error control through alpha spending functions and information-based boundaries. Modern applications extend beyond traditional efficacy testing to encompass adaptive designs, platform trials, and hybrid approaches that maintain regulatory acceptance while providing operational flexibility.\\n\\n| Design Element | Traditional Approach | Group Sequential Advantage |\\n|---------------|---------------------|---------------------------|\\n| Sample size | Fixed at design | Potentially reduced through early stopping |\\n| Decision timing | Single final analysis | Multiple planned interim analyses |\\n| Error control | Simple alpha level | Alpha spending across analyses |\\n| Regulatory acceptance | Straightforward | Requires pre-specification and consultation |\\n\\nImplementation success depends on careful pre-specification of all sequential parameters, appropriate software validation, and enhanced data monitoring committee training. The COVID-19 pandemic demonstrated both the value and challenges of flexible designs when enrollment patterns deviate from assumptions. Future applications will likely emphasize platform trial architectures and real-world evidence integration while maintaining statistical rigor.', sources='')]}}\n",
      "\n",
      "\n",
      "{'compile_final_report': {'final_report': \"# Group Sequential Testing\\n\\nGroup sequential testing revolutionizes clinical trial efficiency by enabling interim analyses with pre-planned stopping rules, offering a compelling alternative to traditional fixed-sample designs. This methodology allows trials to terminate early for efficacy, futility, or safety concerns while maintaining statistical validity through carefully constructed boundaries. By incorporating multiple planned analyses throughout the study duration, investigators can make informed decisions about continuing, modifying, or stopping trials based on accumulating evidence, potentially saving time, resources, and exposing fewer participants to ineffective treatments.\\n\\n## Summary\\n\\nGroup sequential testing has matured from simple boundary functions to sophisticated frameworks accommodating complex trial architectures. The methodology balances early stopping opportunities against Type I error control through alpha spending functions and information-based boundaries. Modern applications extend beyond traditional efficacy testing to encompass adaptive designs, platform trials, and hybrid approaches that maintain regulatory acceptance while providing operational flexibility.\\n\\n| Design Element | Traditional Approach | Group Sequential Advantage |\\n|---------------|---------------------|---------------------------|\\n| Sample size | Fixed at design | Potentially reduced through early stopping |\\n| Decision timing | Single final analysis | Multiple planned interim analyses |\\n| Error control | Simple alpha level | Alpha spending across analyses |\\n| Regulatory acceptance | Straightforward | Requires pre-specification and consultation |\\n\\nImplementation success depends on careful pre-specification of all sequential parameters, appropriate software validation, and enhanced data monitoring committee training. The COVID-19 pandemic demonstrated both the value and challenges of flexible designs when enrollment patterns deviate from assumptions. Future applications will likely emphasize platform trial architectures and real-world evidence integration while maintaining statistical rigor.\\n\\n## Statistical Framework and Stopping Boundaries\\n\\n**Group sequential testing requires careful balance between early stopping opportunities and Type I error control through mathematically rigorous boundary frameworks that extend beyond traditional efficacy-only designs.**\\n\\nAlpha spending functions provide the foundation for controlling overall significance levels across multiple interim analyses. The Lan-DeMets approach allows flexible timing of analyses by specifying how the total Type I error rate (typically 0.05) is allocated across planned looks, ensuring statistical validity regardless of when stopping occurs.\\n\\nInformation fractions define the proportion of total planned information available at each interim analysis. These fractions drive boundary calculations and must account for missing data patterns and endpoint-specific accumulation rates.\\n\\nThree primary boundary types dominate practice:\\n\\n* **Pocock boundaries** maintain constant critical values across all analyses, enabling easier interpretation but requiring larger sample sizes\\n* **O'Brien-Fleming boundaries** use conservative early thresholds that relax toward standard levels, preserving power while allowing early efficacy detection  \\n* **Wang-Tsiatis boundaries** offer flexible parameterization between Pocock and O'Brien-Fleming extremes\\n\\nModern applications extend to changing primary endpoints mid-trial through flexible boundary adjustments. LinkedIn's experimentation platform demonstrates practical trade-offs: O'Brien-Fleming boundaries reduce false positives in early analyses but require stronger evidence for early termination.\\n\\n## Types of Group Sequential Designs and Applications\\n\\n**Group sequential designs have evolved from simple two-arm comparisons to sophisticated multi-stage frameworks that accommodate complex trial architectures while maintaining statistical rigor.**\\n\\nClassical designs form the foundation with well-established boundary functions. O'Brien-Fleming boundaries provide conservative early stopping with α-spending concentrated at final analysis, making them ideal for confirmatory trials requiring high evidence standards. Pocock boundaries distribute α equally across analyses, offering simpler implementation but demanding larger sample sizes.\\n\\nAdaptive designs enable protocol modifications based on accumulating data. Sample size re-estimation addresses initial planning uncertainties, while population enrichment focuses recruitment on responsive subgroups. These designs require careful pre-specification to maintain statistical validity.\\n\\nPlatform trials represent the most complex application, allowing multiple treatments to enter and exit dynamically. They require sophisticated multiple comparison procedures and online error rate control as demonstrated in COVID-19 vaccine trials where treatments were added sequentially.\\n\\nHybrid approaches combine fixed and adaptive elements, balancing operational flexibility with regulatory acceptance. The choice depends on study objectives, regulatory pathway, and institutional capacity for complex interim decision-making.\\n\\n| Design Type | Boundary Characteristic | Optimal Application |\\n|-------------|------------------------|-------------------|\\n| O'Brien-Fleming | Conservative early, liberal late | Confirmatory trials |\\n| Pocock | Constant across analyses | Exploratory studies |\\n| Adaptive | Data-driven modifications | Uncertain populations |\\n\\n## Implementation Considerations and Regulatory Guidance\\n\\n**Information fraction calculations require careful definition of statistical information rather than simple sample size ratios, particularly when dealing with time-to-event endpoints or unequal allocation schemes.** This fundamental concept drives all subsequent implementation decisions.\\n\\nSample size calculations must account for information fractions and spending functions, with validation across multiple platforms. The alpha spending function approach provides flexible boundary construction, allowing investigators to specify spending rates at planned interim analyses without rigid pre-commitment to specific critical values.\\n\\nSoftware tools like East, PASS, and R's gsDesign package handle sequential boundaries effectively. Recent simulation methods enable practical sample size calculations by incorporating realistic assumptions about enrollment patterns, dropout rates, and effect size uncertainty.\\n\\nData monitoring committees require enhanced training on information-based stopping rules and access to updated boundary calculations at each interim analysis. The COVID-19 pandemic demonstrated how enrollment disruptions can affect information accrual timing, making flexible spending functions essential for maintaining statistical validity.\\n\\nRegulatory agencies expect comprehensive statistical analysis plans detailing interim timing rationale, alpha spending justification, and clear stopping criteria. FDA guidance emphasizes pre-specification of all sequential testing parameters and early consultation to ensure design acceptance before trial initiation.\\n\\n## Conclusion and Key Takeaways\\n\\nGroup sequential testing offers powerful early stopping capabilities while maintaining statistical rigor, but implementation complexity varies significantly across design types. The choice between boundary approaches involves fundamental trade-offs between early detection sensitivity and sample size requirements.\\n\\n| Design Type | Primary Advantage | Key Limitation | Best Use Case |\\n|-------------|------------------|----------------|---------------|\\n| O'Brien-Fleming | Preserves power, conservative early stopping | Requires strong early evidence | Confirmatory trials |\\n| Pocock | Simple interpretation, flexible stopping | Larger sample sizes needed | Exploratory studies |\\n| Adaptive | Protocol flexibility, uncertainty handling | Complex implementation | Unknown populations |\\n| Wang-Tsiatis | Customizable boundary shapes | Parameter selection complexity | Tailored applications |\\n\\nFuture directions emphasize platform trials and real-world evidence integration, driven by pandemic-era innovations in flexible trial design. The evolution toward information-based rather than sample-based stopping criteria represents a fundamental shift requiring enhanced statistical expertise and regulatory collaboration. Success depends on pre-specification rigor, appropriate software implementation, and data monitoring committee sophistication in managing complex interim decision frameworks.\\n\\n## Sources Used\\n\\n### Sources for Section: Statistical Framework and Stopping Boundaries\\n\\n================================================================================\\nSEARCH ITERATION 1 - RAG RESULTS\\n================================================================================\\n\\nKohavi: LinkedIn Post (New_AB_Pattern_Reproduction_Results), Section: unknown\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 3. Primacy and newness effects.\\n===\\nKohavi: LinkedIn Post (Lead_with_Clear_Memorable_Leadership_Principl), Section: unknown\\n===\\nKohavi: Why are Power Calculators Giving Different Results, Section: Untitled\\n===\\nKohavi: Online Controlled Experiments at Large Scale, Section: 4.3 Alerts and Aborting Bad Experiments\\n===\\n\\n================================================================================\\nSEARCH ITERATION 2 - ARXIV RESULTS\\n================================================================================\\n\\nExact sequential single-arm trial design with curtailment for binary endpoint\\n===\\nURL: http://arxiv.org/abs/2303.17091v1\\n===\\nInterim Analysis in Sequential Multiple Assignment Randomized Trials for Survival Outcomes\\n===\\nURL: http://arxiv.org/abs/2504.03143v1\\n===\\nBayesian response adaptive randomization design with a composite endpoint of mortality and morbidity\\n===\\nURL: http://arxiv.org/abs/2208.08472v3\\n===\\n\\n================================================================================\\nSEARCH ITERATION 3 - TAVILY RESULTS\\n================================================================================\\n\\nDefining information fractions in group sequential clinical trials with ...\\n===\\nURL: https://www.sciencedirect.com/science/article/pii/S2451865418300097\\n===\\nFlexible Stopping Boundaries When Changing Primary Endpoints after ...\\n===\\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC4024106/\\n===\\nPDF\\n===\\nURL: https://www.biostat.wisc.edu/~chappell/641/papers/paper35.pdf\\n===\\n9.6 - Alpha Spending Function approach | STAT 509 - Statistics Online\\n===\\nURL: https://online.stat.psu.edu/stat509/lesson/9/9.6\\n===\\nPDF\\n===\\nURL: https://eclass.uoa.gr/modules/document/file.php/MATH301/PracticalSession3/LanDeMets.pdf\\n===\\nFull source content limited to 1000 tokens\\n\\n### Sources for Section: Types of Group Sequential Designs and Applications\\n\\n================================================================================\\nSEARCH ITERATION 1 - RAG RESULTS\\n================================================================================\\n\\nKohavi: Online Controlled Experiments and AB Tests, Section: Increasing Experiment Sensitivity\\n===\\nKohavi: Online Controlled Experiments and AB Tests, Section: Sample size.\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: Abstract\\n===\\nKohavi: Online Controlled Experiments at Large Scale, Section: 3.1 Why Controlled Experiments?\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 3.6 Limitations\\n===\\n\\n================================================================================\\nSEARCH ITERATION 2 - ARXIV RESULTS\\n================================================================================\\n\\nInterim Monitoring of Sequential Multiple Assignment Randomized Trials Using Partial Information\\n===\\nURL: http://arxiv.org/abs/2209.06306v2\\n===\\nInterim Analysis in Sequential Multiple Assignment Randomized Trials for Survival Outcomes\\n===\\nURL: http://arxiv.org/abs/2504.03143v1\\n===\\nOnline control of the False Discovery Rate in group-sequential platform trials\\n===\\nURL: http://arxiv.org/abs/2112.10619v1\\n===\\n\\n================================================================================\\nSEARCH ITERATION 3 - TAVILY RESULTS\\n================================================================================\\n\\nPDF\\n===\\nURL: https://mwsug.org/proceedings/2016/PH/MWSUG-2016-PH06.pdf\\n===\\nFull source content limited to 1000 tokens \\n\\n6 Deriving group sequential designs - gsDesign Technical Manual\\n===\\nURL: https://keaven.github.io/gsd-tech-manual/gsdesign.html\\n===\\nFull source content limited to 1000 tokens \\n\\nGuidance on interim analysis methods in clinical trials - PMC\\n===\\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC10260346/\\n===\\n9.5 - Frequentist Methods: O'Brien-Fleming, Pocock, Haybittle-Peto\\n===\\nURL: https://online.stat.psu.edu/stat509/lesson/9/9.5\\n===\\nFull source content limited to 1000 tokens \\n\\nInterim Analyses During Group Sequential Clinical Trials\\n===\\nURL: https://jamanetwork.com/journals/jama/fullarticle/2784821\\n===\\n\\n### Sources for Section: Implementation Considerations and Regulatory Guidance\\n\\n================================================================================\\nSEARCH ITERATION 1 - RAG RESULTS\\n================================================================================\\n\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 6.2.3 Determine the minimum sample size\\n===\\nKohavi: Online Controlled Experiments at Large Scale, Section: 5.1 False Positives\\n===\\nKohavi: The Surprising Power of Online Experiments, Section: Center-of-excellence model\\n===\\nKohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 5.2 Assignment method\\n===\\nKohavi: Why are Power Calculators Giving Different Results, Section: Explaining the differences:\\n===\\n\\n================================================================================\\nSEARCH ITERATION 2 - ARXIV RESULTS\\n================================================================================\\n\\nClinical trials impacted by the COVID-19 pandemic: Adaptive designs to the rescue?\\n===\\nURL: http://arxiv.org/abs/2005.13979v1\\n===\\nConfidence intervals for adaptive trial designs II: Case study and practical guidance\\n===\\nURL: http://arxiv.org/abs/2411.08771v1\\n===\\nConfidence intervals for adaptive trial designs I: A methodological review\\n===\\nURL: http://arxiv.org/abs/2411.08495v1\\n===\\n\\n================================================================================\\nSEARCH ITERATION 3 - TAVILY RESULTS\\n================================================================================\\n\\nDefining information fractions in group sequential clinical trials with ...\\n===\\nURL: https://www.sciencedirect.com/science/article/pii/S2451865418300097\\n===\\nA Practical Simulation Method to Calculate Sample Size of Group ...\\n===\\nURL: https://pmc.ncbi.nlm.nih.gov/articles/PMC3434206/\\n===\\n8 Spending functions - Group Sequential Designs Made Easy\\n===\\nURL: https://keaven.github.io/gsd-shiny/spending.html\\n===\\nFull source content limited to 1000 tokens \\n\\nInterim Analyses During Group Sequential Clinical Trials\\n===\\nURL: https://jamanetwork.com/journals/jama/fullarticle/2784821\\n===\\n9.6 - Alpha Spending Function approach | STAT 509 - Statistics Online\\n===\\nURL: https://online.stat.psu.edu/stat509/lesson/9/9.6\\n===\\n\\n\"}}\n",
      "\n",
      "\n",
      "🎉 Final report generated! 🎉\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Group Sequential Testing Report\n",
       "\n",
       "# Group Sequential Testing\n",
       "\n",
       "Group sequential testing revolutionizes clinical trial efficiency by enabling interim analyses with pre-planned stopping rules, offering a compelling alternative to traditional fixed-sample designs. This methodology allows trials to terminate early for efficacy, futility, or safety concerns while maintaining statistical validity through carefully constructed boundaries. By incorporating multiple planned analyses throughout the study duration, investigators can make informed decisions about continuing, modifying, or stopping trials based on accumulating evidence, potentially saving time, resources, and exposing fewer participants to ineffective treatments.\n",
       "\n",
       "## Summary\n",
       "\n",
       "Group sequential testing has matured from simple boundary functions to sophisticated frameworks accommodating complex trial architectures. The methodology balances early stopping opportunities against Type I error control through alpha spending functions and information-based boundaries. Modern applications extend beyond traditional efficacy testing to encompass adaptive designs, platform trials, and hybrid approaches that maintain regulatory acceptance while providing operational flexibility.\n",
       "\n",
       "| Design Element | Traditional Approach | Group Sequential Advantage |\n",
       "|---------------|---------------------|---------------------------|\n",
       "| Sample size | Fixed at design | Potentially reduced through early stopping |\n",
       "| Decision timing | Single final analysis | Multiple planned interim analyses |\n",
       "| Error control | Simple alpha level | Alpha spending across analyses |\n",
       "| Regulatory acceptance | Straightforward | Requires pre-specification and consultation |\n",
       "\n",
       "Implementation success depends on careful pre-specification of all sequential parameters, appropriate software validation, and enhanced data monitoring committee training. The COVID-19 pandemic demonstrated both the value and challenges of flexible designs when enrollment patterns deviate from assumptions. Future applications will likely emphasize platform trial architectures and real-world evidence integration while maintaining statistical rigor.\n",
       "\n",
       "## Statistical Framework and Stopping Boundaries\n",
       "\n",
       "**Group sequential testing requires careful balance between early stopping opportunities and Type I error control through mathematically rigorous boundary frameworks that extend beyond traditional efficacy-only designs.**\n",
       "\n",
       "Alpha spending functions provide the foundation for controlling overall significance levels across multiple interim analyses. The Lan-DeMets approach allows flexible timing of analyses by specifying how the total Type I error rate (typically 0.05) is allocated across planned looks, ensuring statistical validity regardless of when stopping occurs.\n",
       "\n",
       "Information fractions define the proportion of total planned information available at each interim analysis. These fractions drive boundary calculations and must account for missing data patterns and endpoint-specific accumulation rates.\n",
       "\n",
       "Three primary boundary types dominate practice:\n",
       "\n",
       "* **Pocock boundaries** maintain constant critical values across all analyses, enabling easier interpretation but requiring larger sample sizes\n",
       "* **O'Brien-Fleming boundaries** use conservative early thresholds that relax toward standard levels, preserving power while allowing early efficacy detection  \n",
       "* **Wang-Tsiatis boundaries** offer flexible parameterization between Pocock and O'Brien-Fleming extremes\n",
       "\n",
       "Modern applications extend to changing primary endpoints mid-trial through flexible boundary adjustments. LinkedIn's experimentation platform demonstrates practical trade-offs: O'Brien-Fleming boundaries reduce false positives in early analyses but require stronger evidence for early termination.\n",
       "\n",
       "## Types of Group Sequential Designs and Applications\n",
       "\n",
       "**Group sequential designs have evolved from simple two-arm comparisons to sophisticated multi-stage frameworks that accommodate complex trial architectures while maintaining statistical rigor.**\n",
       "\n",
       "Classical designs form the foundation with well-established boundary functions. O'Brien-Fleming boundaries provide conservative early stopping with α-spending concentrated at final analysis, making them ideal for confirmatory trials requiring high evidence standards. Pocock boundaries distribute α equally across analyses, offering simpler implementation but demanding larger sample sizes.\n",
       "\n",
       "Adaptive designs enable protocol modifications based on accumulating data. Sample size re-estimation addresses initial planning uncertainties, while population enrichment focuses recruitment on responsive subgroups. These designs require careful pre-specification to maintain statistical validity.\n",
       "\n",
       "Platform trials represent the most complex application, allowing multiple treatments to enter and exit dynamically. They require sophisticated multiple comparison procedures and online error rate control as demonstrated in COVID-19 vaccine trials where treatments were added sequentially.\n",
       "\n",
       "Hybrid approaches combine fixed and adaptive elements, balancing operational flexibility with regulatory acceptance. The choice depends on study objectives, regulatory pathway, and institutional capacity for complex interim decision-making.\n",
       "\n",
       "| Design Type | Boundary Characteristic | Optimal Application |\n",
       "|-------------|------------------------|-------------------|\n",
       "| O'Brien-Fleming | Conservative early, liberal late | Confirmatory trials |\n",
       "| Pocock | Constant across analyses | Exploratory studies |\n",
       "| Adaptive | Data-driven modifications | Uncertain populations |\n",
       "\n",
       "## Implementation Considerations and Regulatory Guidance\n",
       "\n",
       "**Information fraction calculations require careful definition of statistical information rather than simple sample size ratios, particularly when dealing with time-to-event endpoints or unequal allocation schemes.** This fundamental concept drives all subsequent implementation decisions.\n",
       "\n",
       "Sample size calculations must account for information fractions and spending functions, with validation across multiple platforms. The alpha spending function approach provides flexible boundary construction, allowing investigators to specify spending rates at planned interim analyses without rigid pre-commitment to specific critical values.\n",
       "\n",
       "Software tools like East, PASS, and R's gsDesign package handle sequential boundaries effectively. Recent simulation methods enable practical sample size calculations by incorporating realistic assumptions about enrollment patterns, dropout rates, and effect size uncertainty.\n",
       "\n",
       "Data monitoring committees require enhanced training on information-based stopping rules and access to updated boundary calculations at each interim analysis. The COVID-19 pandemic demonstrated how enrollment disruptions can affect information accrual timing, making flexible spending functions essential for maintaining statistical validity.\n",
       "\n",
       "Regulatory agencies expect comprehensive statistical analysis plans detailing interim timing rationale, alpha spending justification, and clear stopping criteria. FDA guidance emphasizes pre-specification of all sequential testing parameters and early consultation to ensure design acceptance before trial initiation.\n",
       "\n",
       "## Conclusion and Key Takeaways\n",
       "\n",
       "Group sequential testing offers powerful early stopping capabilities while maintaining statistical rigor, but implementation complexity varies significantly across design types. The choice between boundary approaches involves fundamental trade-offs between early detection sensitivity and sample size requirements.\n",
       "\n",
       "| Design Type | Primary Advantage | Key Limitation | Best Use Case |\n",
       "|-------------|------------------|----------------|---------------|\n",
       "| O'Brien-Fleming | Preserves power, conservative early stopping | Requires strong early evidence | Confirmatory trials |\n",
       "| Pocock | Simple interpretation, flexible stopping | Larger sample sizes needed | Exploratory studies |\n",
       "| Adaptive | Protocol flexibility, uncertainty handling | Complex implementation | Unknown populations |\n",
       "| Wang-Tsiatis | Customizable boundary shapes | Parameter selection complexity | Tailored applications |\n",
       "\n",
       "Future directions emphasize platform trials and real-world evidence integration, driven by pandemic-era innovations in flexible trial design. The evolution toward information-based rather than sample-based stopping criteria represents a fundamental shift requiring enhanced statistical expertise and regulatory collaboration. Success depends on pre-specification rigor, appropriate software implementation, and data monitoring committee sophistication in managing complex interim decision frameworks.\n",
       "\n",
       "## Sources Used\n",
       "\n",
       "### Sources for Section: Statistical Framework and Stopping Boundaries\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 1 - RAG RESULTS\n",
       "================================================================================\n",
       "\n",
       "Kohavi: LinkedIn Post (New_AB_Pattern_Reproduction_Results), Section: unknown\n",
       "===\n",
       "Kohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 3. Primacy and newness effects.\n",
       "===\n",
       "Kohavi: LinkedIn Post (Lead_with_Clear_Memorable_Leadership_Principl), Section: unknown\n",
       "===\n",
       "Kohavi: Why are Power Calculators Giving Different Results, Section: Untitled\n",
       "===\n",
       "Kohavi: Online Controlled Experiments at Large Scale, Section: 4.3 Alerts and Aborting Bad Experiments\n",
       "===\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 2 - ARXIV RESULTS\n",
       "================================================================================\n",
       "\n",
       "Exact sequential single-arm trial design with curtailment for binary endpoint\n",
       "===\n",
       "URL: http://arxiv.org/abs/2303.17091v1\n",
       "===\n",
       "Interim Analysis in Sequential Multiple Assignment Randomized Trials for Survival Outcomes\n",
       "===\n",
       "URL: http://arxiv.org/abs/2504.03143v1\n",
       "===\n",
       "Bayesian response adaptive randomization design with a composite endpoint of mortality and morbidity\n",
       "===\n",
       "URL: http://arxiv.org/abs/2208.08472v3\n",
       "===\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 3 - TAVILY RESULTS\n",
       "================================================================================\n",
       "\n",
       "Defining information fractions in group sequential clinical trials with ...\n",
       "===\n",
       "URL: https://www.sciencedirect.com/science/article/pii/S2451865418300097\n",
       "===\n",
       "Flexible Stopping Boundaries When Changing Primary Endpoints after ...\n",
       "===\n",
       "URL: https://pmc.ncbi.nlm.nih.gov/articles/PMC4024106/\n",
       "===\n",
       "PDF\n",
       "===\n",
       "URL: https://www.biostat.wisc.edu/~chappell/641/papers/paper35.pdf\n",
       "===\n",
       "9.6 - Alpha Spending Function approach | STAT 509 - Statistics Online\n",
       "===\n",
       "URL: https://online.stat.psu.edu/stat509/lesson/9/9.6\n",
       "===\n",
       "PDF\n",
       "===\n",
       "URL: https://eclass.uoa.gr/modules/document/file.php/MATH301/PracticalSession3/LanDeMets.pdf\n",
       "===\n",
       "Full source content limited to 1000 tokens\n",
       "\n",
       "### Sources for Section: Types of Group Sequential Designs and Applications\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 1 - RAG RESULTS\n",
       "================================================================================\n",
       "\n",
       "Kohavi: Online Controlled Experiments and AB Tests, Section: Increasing Experiment Sensitivity\n",
       "===\n",
       "Kohavi: Online Controlled Experiments and AB Tests, Section: Sample size.\n",
       "===\n",
       "Kohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: Abstract\n",
       "===\n",
       "Kohavi: Online Controlled Experiments at Large Scale, Section: 3.1 Why Controlled Experiments?\n",
       "===\n",
       "Kohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 3.6 Limitations\n",
       "===\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 2 - ARXIV RESULTS\n",
       "================================================================================\n",
       "\n",
       "Interim Monitoring of Sequential Multiple Assignment Randomized Trials Using Partial Information\n",
       "===\n",
       "URL: http://arxiv.org/abs/2209.06306v2\n",
       "===\n",
       "Interim Analysis in Sequential Multiple Assignment Randomized Trials for Survival Outcomes\n",
       "===\n",
       "URL: http://arxiv.org/abs/2504.03143v1\n",
       "===\n",
       "Online control of the False Discovery Rate in group-sequential platform trials\n",
       "===\n",
       "URL: http://arxiv.org/abs/2112.10619v1\n",
       "===\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 3 - TAVILY RESULTS\n",
       "================================================================================\n",
       "\n",
       "PDF\n",
       "===\n",
       "URL: https://mwsug.org/proceedings/2016/PH/MWSUG-2016-PH06.pdf\n",
       "===\n",
       "Full source content limited to 1000 tokens \n",
       "\n",
       "6 Deriving group sequential designs - gsDesign Technical Manual\n",
       "===\n",
       "URL: https://keaven.github.io/gsd-tech-manual/gsdesign.html\n",
       "===\n",
       "Full source content limited to 1000 tokens \n",
       "\n",
       "Guidance on interim analysis methods in clinical trials - PMC\n",
       "===\n",
       "URL: https://pmc.ncbi.nlm.nih.gov/articles/PMC10260346/\n",
       "===\n",
       "9.5 - Frequentist Methods: O'Brien-Fleming, Pocock, Haybittle-Peto\n",
       "===\n",
       "URL: https://online.stat.psu.edu/stat509/lesson/9/9.5\n",
       "===\n",
       "Full source content limited to 1000 tokens \n",
       "\n",
       "Interim Analyses During Group Sequential Clinical Trials\n",
       "===\n",
       "URL: https://jamanetwork.com/journals/jama/fullarticle/2784821\n",
       "===\n",
       "\n",
       "### Sources for Section: Implementation Considerations and Regulatory Guidance\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 1 - RAG RESULTS\n",
       "================================================================================\n",
       "\n",
       "Kohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 6.2.3 Determine the minimum sample size\n",
       "===\n",
       "Kohavi: Online Controlled Experiments at Large Scale, Section: 5.1 False Positives\n",
       "===\n",
       "Kohavi: The Surprising Power of Online Experiments, Section: Center-of-excellence model\n",
       "===\n",
       "Kohavi: Controlled Experiments on the Web Survey and Practical Guide, Section: 5.2 Assignment method\n",
       "===\n",
       "Kohavi: Why are Power Calculators Giving Different Results, Section: Explaining the differences:\n",
       "===\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 2 - ARXIV RESULTS\n",
       "================================================================================\n",
       "\n",
       "Clinical trials impacted by the COVID-19 pandemic: Adaptive designs to the rescue?\n",
       "===\n",
       "URL: http://arxiv.org/abs/2005.13979v1\n",
       "===\n",
       "Confidence intervals for adaptive trial designs II: Case study and practical guidance\n",
       "===\n",
       "URL: http://arxiv.org/abs/2411.08771v1\n",
       "===\n",
       "Confidence intervals for adaptive trial designs I: A methodological review\n",
       "===\n",
       "URL: http://arxiv.org/abs/2411.08495v1\n",
       "===\n",
       "\n",
       "================================================================================\n",
       "SEARCH ITERATION 3 - TAVILY RESULTS\n",
       "================================================================================\n",
       "\n",
       "Defining information fractions in group sequential clinical trials with ...\n",
       "===\n",
       "URL: https://www.sciencedirect.com/science/article/pii/S2451865418300097\n",
       "===\n",
       "A Practical Simulation Method to Calculate Sample Size of Group ...\n",
       "===\n",
       "URL: https://pmc.ncbi.nlm.nih.gov/articles/PMC3434206/\n",
       "===\n",
       "8 Spending functions - Group Sequential Designs Made Easy\n",
       "===\n",
       "URL: https://keaven.github.io/gsd-shiny/spending.html\n",
       "===\n",
       "Full source content limited to 1000 tokens \n",
       "\n",
       "Interim Analyses During Group Sequential Clinical Trials\n",
       "===\n",
       "URL: https://jamanetwork.com/journals/jama/fullarticle/2784821\n",
       "===\n",
       "9.6 - Alpha Spending Function approach | STAT 509 - Statistics Online\n",
       "===\n",
       "URL: https://online.stat.psu.edu/stat509/lesson/9/9.6\n",
       "===\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await approve_plan()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
